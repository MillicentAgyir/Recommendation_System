{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6366bbd",
   "metadata": {},
   "source": [
    "## MODELLING AND EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f5a15",
   "metadata": {},
   "source": [
    " Goal: To build a practical **offline recommender** that generates high-quality top-K suggestions using a multi-method candidate pool and simple business-aware re-ranking. We evaluate with standard ranking metrics on a **time-ordered split** to mimic production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842d12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import coo_matrix, csr_matrix, diags\n",
    "from scipy.sparse.linalg import svds\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379754ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports & Config\n",
    "\n",
    "# --- global config ---\n",
    "K = 10                         # top-K for evaluation\n",
    "EVENT_WEIGHTS = {'view': 1.0, 'addtocart': 3.0, 'transaction': 5.0}\n",
    "MIN_TRAIN_INTERACTIONS = 2     # drop ultra-sparse train users\n",
    "CHUNK_USERS = 25000            # evaluation in chunks to avoid long single loops\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../Data/Cleaned Dataset/final_merged_events.csv\")\n",
    "\n",
    "# Ensure timestamp as datetime (use event_time if you prefer)\n",
    "if 'event_time' in df.columns:\n",
    "    df['event_time'] = pd.to_datetime(df['event_time'], errors='coerce')\n",
    "    df['ts_dt'] = df['event_time']\n",
    "else:\n",
    "    df['ts_dt'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce')\n",
    "\n",
    "# Keep only needed cols\n",
    "df = df[['visitorid','itemid','event','ts_dt']].dropna(subset=['visitorid','itemid','event','ts_dt']).copy()\n",
    "\n",
    "# =========================\n",
    "# 2) Weighting & Train/Test Split (chronological leave-last-out)\n",
    "# =========================\n",
    "df['w'] = df['event'].map(EVENT_WEIGHTS).fillna(0.5)  # unseen events get small weight\n",
    "\n",
    "# sort by time per user\n",
    "df = df.sort_values(['visitorid','ts_dt'])\n",
    "\n",
    "# last interaction per user -> test; others -> train\n",
    "last_idx = df.groupby('visitorid')['ts_dt'].idxmax()\n",
    "df['split'] = 'train'\n",
    "df.loc[last_idx, 'split'] = 'test'\n",
    "\n",
    "train = df[df['split']=='train'].copy()\n",
    "test  = df[df['split']=='test'].copy()\n",
    "\n",
    "# drop users with too few train interactions (optional, improves CF stability)\n",
    "train_counts = train['visitorid'].value_counts()\n",
    "keep_users = set(train_counts[train_counts >= MIN_TRAIN_INTERACTIONS].index)\n",
    "train = train[train['visitorid'].isin(keep_users)]\n",
    "test  = test[test['visitorid'].isin(keep_users)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1cb229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix: (199983, 125261) | nnz: 722658\n",
      "Eval users (with test truth & in-train): 190636\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# 3) Build ID Mappings & Sparse User–Item Matrix (train)\n",
    "# =========================\n",
    "unique_users = train['visitorid'].unique()\n",
    "unique_items = train['itemid'].unique()\n",
    "\n",
    "user2idx = {u:i for i,u in enumerate(unique_users)}\n",
    "item2idx = {i:j for j,i in enumerate(unique_items)}\n",
    "idx2user = np.array(unique_users)\n",
    "idx2item = np.array(unique_items)\n",
    "\n",
    "# remap train\n",
    "tr_u = train['visitorid'].map(user2idx).values\n",
    "tr_i = train['itemid'].map(item2idx).values\n",
    "tr_w = train['w'].values\n",
    "\n",
    "# sum duplicates by coo -> csr\n",
    "X_train = coo_matrix((tr_w, (tr_u, tr_i)), shape=(len(unique_users), len(unique_items))).tocsr()\n",
    "\n",
    "n_users, n_items = X_train.shape\n",
    "print(\"Train matrix:\", X_train.shape, \"| nnz:\", X_train.nnz)\n",
    "\n",
    "# seen items per user (train)\n",
    "seen_train = {}\n",
    "X_train_csr = X_train.tocsr()\n",
    "for u in range(n_users):\n",
    "    start, end = X_train_csr.indptr[u], X_train_csr.indptr[u+1]\n",
    "    seen_train[u] = set(X_train_csr.indices[start:end])\n",
    "\n",
    "# test ground truth (only items that exist in train space)\n",
    "test_truth = defaultdict(set)\n",
    "test_mapped = test[test['itemid'].isin(item2idx)].copy()\n",
    "for r in test_mapped.itertuples(index=False):\n",
    "    u = r.visitorid\n",
    "    i = r.itemid\n",
    "    test_truth[u].add(i)\n",
    "\n",
    "# restrict evaluation users to those present in train mapping and with >0 ground truth\n",
    "eval_users = [u for u in test_truth.keys() if u in user2idx]\n",
    "print(\"Eval users (with test truth & in-train):\", len(eval_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Utility: Metrics\n",
    "\n",
    "def recall_at_k(true_items, rec_list, k=10):\n",
    "    if not true_items: return 0.0\n",
    "    return len(set(rec_list[:k]) & set(true_items)) / len(true_items)\n",
    "\n",
    "def ap_at_k(true_items, rec_list, k=10):\n",
    "    if not true_items: return 0.0\n",
    "    true = set(true_items)\n",
    "    hits, ap = 0, 0.0\n",
    "    for i, it in enumerate(rec_list[:k], start=1):\n",
    "        if it in true:\n",
    "            hits += 1\n",
    "            ap += hits / i\n",
    "    return ap / min(len(true_items), k)\n",
    "\n",
    "def ndcg_at_k(true_items, rec_list, k=10):\n",
    "    if not true_items: return 0.0\n",
    "    true = set(true_items)\n",
    "    dcg = 0.0\n",
    "    for i, it in enumerate(rec_list[:k], start=1):\n",
    "        if it in true:\n",
    "            dcg += 1.0 / np.log2(i+1)\n",
    "    ideal = min(len(true_items), k)\n",
    "    idcg = sum(1.0 / np.log2(i+1) for i in range(1, ideal+1))\n",
    "    return dcg / idcg if idcg > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f39dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) Popularity Baseline\n",
    "# =========================\n",
    "# global top items by train weight (heavier weight => more important)\n",
    "item_pop = np.asarray(X_train.sum(axis=0)).ravel()\n",
    "pop_order = np.argsort(-item_pop)  # item indices (train-space)\n",
    "\n",
    "def toplist_pop(u_idx, k=K):\n",
    "    # same list for all users (filter seen to avoid duplicates)\n",
    "    seen = seen_train.get(u_idx, set())\n",
    "    out = []\n",
    "    for j in pop_order:\n",
    "        if j not in seen:\n",
    "            out.append(j)\n",
    "            if len(out) == k: break\n",
    "    return [idx2item[j] for j in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe66203",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 6) Weightings: TF-IDF & BM25\n",
    "# =========================\n",
    "def tfidf_weight(X):\n",
    "    \"\"\" Right-multiply by IDF on items (columns). \"\"\"\n",
    "    # df_i: number of users who interacted with item i\n",
    "    df_i = np.diff(X.tocsc().indptr)  # fast column nnz\n",
    "    idf = np.log((X.shape[0] + 1) / (df_i + 1)) + 1.0\n",
    "    W = diags(idf)\n",
    "    return (X @ W).tocsr()\n",
    "\n",
    "def bm25_weight(X, K1=100, B=0.8):\n",
    "    \"\"\"\n",
    "    BM25 for implicit feedback treating each user-row as a document.\n",
    "    \"\"\"\n",
    "    X = X.tocsr().astype(np.float64)\n",
    "    # document lengths per user\n",
    "    row_sums = np.asarray(X.sum(axis=1)).ravel()\n",
    "    avg_len = row_sums.mean() + 1e-9\n",
    "\n",
    "    # df per item\n",
    "    df_i = np.diff(X.tocsc().indptr).astype(np.float64)\n",
    "    idf = np.log((X.shape[0] - df_i + 0.5) / (df_i + 0.5))\n",
    "    idf = np.maximum(idf, 0)  # clamp negatives\n",
    "\n",
    "    X_bm25 = X.copy().tocoo()\n",
    "    # term frequency (here: weights) with BM25 saturation\n",
    "    norm = K1 * (1 - B + B * (row_sums[X_bm25.row] / avg_len))\n",
    "    X_bm25.data = (X_bm25.data * (K1 + 1)) / (X_bm25.data + norm)\n",
    "    # apply idf\n",
    "    X_bm25.data *= idf[X_bm25.col]\n",
    "    return X_bm25.tocsr()\n",
    "\n",
    "# Precompute variants\n",
    "X_RAW   = X_train\n",
    "X_TFIDF = tfidf_weight(X_train)\n",
    "X_BM25  = bm25_weight(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f9f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 7) Item–Item Cosine (memory-safe, no full similarity)\n",
    "#    scores = (w * C^T) * C, where C = column-L2-normalized X\n",
    "# =========================\n",
    "def prepare_itemcosine_inputs(X):\n",
    "    # column norms\n",
    "    col_sq = np.ravel(X.power(2).sum(axis=0))\n",
    "    col_norm = np.sqrt(col_sq) + 1e-12\n",
    "    inv = 1.0 / col_norm\n",
    "    C = (X @ diags(inv)).tocsr()  # users x items, col-normalized\n",
    "    return C, inv  # inv kept just in case\n",
    "\n",
    "def recommend_itemcosine(u_idx, X, C, k=K):\n",
    "    \"\"\"Recommend via item–item cosine using two-step multiplication (sparse-safe).\"\"\"\n",
    "    seen = seen_train.get(u_idx, set())\n",
    "    # w = user row over items\n",
    "    w = X[u_idx, :]                      # 1 x n_items\n",
    "    # y = w * C^T  -> shape (1, n_users)\n",
    "    y = (w @ C.T)                        # sparse * sparse -> sparse\n",
    "    # scores = y * C -> shape (1, n_items)\n",
    "    s = (y @ C).toarray().ravel()        # dense 1D\n",
    "    if seen:\n",
    "        s[list(seen)] = -np.inf\n",
    "    # top-k\n",
    "    top = np.argpartition(-s, k)[:k]\n",
    "    top = top[np.argsort(-s[top])]\n",
    "    return [idx2item[j] for j in top]\n",
    "\n",
    "# prepare cosine inputs for each weighting\n",
    "C_RAW,   _ = prepare_itemcosine_inputs(X_RAW)\n",
    "C_TFIDF, _ = prepare_itemcosine_inputs(X_TFIDF)\n",
    "C_BM25,  _ = prepare_itemcosine_inputs(X_BM25)\n",
    "\n",
    "# wrappers\n",
    "def toplist_itemcosine_raw(u_idx, k=K):   return recommend_itemcosine(u_idx, X_RAW,   C_RAW,   k)\n",
    "def toplist_itemcosine_tfidf(u_idx, k=K): return recommend_itemcosine(u_idx, X_TFIDF, C_TFIDF, k)\n",
    "def toplist_itemcosine_bm25(u_idx, k=K):  return recommend_itemcosine(u_idx, X_BM25,  C_BM25,  k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b3855c2",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# 8) SVD Latent Factors (pure SciPy)\n",
    "#    X ≈ U S V^T; use P = U sqrt(S), Q = V sqrt(S) for scoring: score = P[u]·Q^T\n",
    "\n",
    "def train_svd(X, factors=64, random_state=RANDOM_STATE):\n",
    "    U, s, Vt = svds(X.asfptype(), k=factors, which='LM', return_singular_vectors=True)\n",
    "    # sort largest -> smallest\n",
    "    order = np.argsort(-s)\n",
    "    s = s[order]\n",
    "    U = U[:, order]\n",
    "    Vt = Vt[order, :]\n",
    "    Ssqrt = np.sqrt(s)\n",
    "    P = U * Ssqrt   # users x k\n",
    "    Q = (Vt.T * Ssqrt)  # items x k\n",
    "    # L2 normalize rows (optional, often helps)\n",
    "    Pu = np.linalg.norm(P, axis=1, keepdims=True) + 1e-12\n",
    "    Qi = np.linalg.norm(Q, axis=1, keepdims=True) + 1e-12\n",
    "    return (P / Pu), (Q / Qi)\n",
    "\n",
    "def recommend_svd(u_idx, P, Q, k=K):\n",
    "    seen = seen_train.get(u_idx, set())\n",
    "    scores = (P[u_idx, :] @ Q.T)   # 1 x n_items\n",
    "    if seen:\n",
    "        scores[list(seen)] = -np.inf\n",
    "    top = np.argpartition(-scores, k)[:k]\n",
    "    top = top[np.argsort(-scores[top])]\n",
    "    return [idx2item[j] for j in top]\n",
    "\n",
    "# Train SVD on the strongest weighting (BM25 usually best)\n",
    "P_bm25, Q_bm25 = train_svd(X_BM25, factors=64)\n",
    "def toplist_svd_bm25(u_idx, k=K): return recommend_svd(u_idx, P_bm25, Q_bm25, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6da26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Popularity@10] processed: 2000/190636\n",
      "[Popularity@10] processed: 4000/190636\n",
      "[Popularity@10] processed: 6000/190636\n",
      "[Popularity@10] processed: 8000/190636\n",
      "[Popularity@10] processed: 10000/190636\n",
      "[Popularity@10] processed: 12000/190636\n",
      "[Popularity@10] processed: 14000/190636\n",
      "[Popularity@10] processed: 16000/190636\n",
      "[Popularity@10] processed: 18000/190636\n",
      "[Popularity@10] processed: 20000/190636\n",
      "[Popularity@10] processed: 22000/190636\n",
      "[Popularity@10] processed: 24000/190636\n",
      "[Popularity@10] processed: 26000/190636\n",
      "[Popularity@10] processed: 28000/190636\n",
      "[Popularity@10] processed: 30000/190636\n",
      "[Popularity@10] processed: 32000/190636\n",
      "[Popularity@10] processed: 34000/190636\n",
      "[Popularity@10] processed: 36000/190636\n",
      "[Popularity@10] processed: 38000/190636\n",
      "[Popularity@10] processed: 40000/190636\n",
      "[Popularity@10] processed: 42000/190636\n",
      "[Popularity@10] processed: 44000/190636\n",
      "[Popularity@10] processed: 46000/190636\n",
      "[Popularity@10] processed: 48000/190636\n",
      "[Popularity@10] processed: 50000/190636\n",
      "[Popularity@10] processed: 52000/190636\n",
      "[Popularity@10] processed: 54000/190636\n",
      "[Popularity@10] processed: 56000/190636\n",
      "[Popularity@10] processed: 58000/190636\n",
      "[Popularity@10] processed: 60000/190636\n",
      "[Popularity@10] processed: 62000/190636\n",
      "[Popularity@10] processed: 64000/190636\n",
      "[Popularity@10] processed: 66000/190636\n",
      "[Popularity@10] processed: 68000/190636\n",
      "[Popularity@10] processed: 70000/190636\n",
      "[Popularity@10] processed: 72000/190636\n",
      "[Popularity@10] processed: 74000/190636\n",
      "[Popularity@10] processed: 76000/190636\n",
      "[Popularity@10] processed: 78000/190636\n",
      "[Popularity@10] processed: 80000/190636\n",
      "[Popularity@10] processed: 82000/190636\n",
      "[Popularity@10] processed: 84000/190636\n",
      "[Popularity@10] processed: 86000/190636\n",
      "[Popularity@10] processed: 88000/190636\n",
      "[Popularity@10] processed: 90000/190636\n",
      "[Popularity@10] processed: 92000/190636\n",
      "[Popularity@10] processed: 94000/190636\n",
      "[Popularity@10] processed: 96000/190636\n",
      "[Popularity@10] processed: 98000/190636\n",
      "[Popularity@10] processed: 100000/190636\n",
      "[Popularity@10] processed: 102000/190636\n",
      "[Popularity@10] processed: 104000/190636\n",
      "[Popularity@10] processed: 106000/190636\n",
      "[Popularity@10] processed: 108000/190636\n",
      "[Popularity@10] processed: 110000/190636\n",
      "[Popularity@10] processed: 112000/190636\n",
      "[Popularity@10] processed: 114000/190636\n",
      "[Popularity@10] processed: 116000/190636\n",
      "[Popularity@10] processed: 118000/190636\n",
      "[Popularity@10] processed: 120000/190636\n",
      "[Popularity@10] processed: 122000/190636\n",
      "[Popularity@10] processed: 124000/190636\n",
      "[Popularity@10] processed: 126000/190636\n",
      "[Popularity@10] processed: 128000/190636\n",
      "[Popularity@10] processed: 130000/190636\n",
      "[Popularity@10] processed: 132000/190636\n",
      "[Popularity@10] processed: 134000/190636\n",
      "[Popularity@10] processed: 136000/190636\n",
      "[Popularity@10] processed: 138000/190636\n",
      "[Popularity@10] processed: 140000/190636\n",
      "[Popularity@10] processed: 142000/190636\n",
      "[Popularity@10] processed: 144000/190636\n",
      "[Popularity@10] processed: 146000/190636\n",
      "[Popularity@10] processed: 148000/190636\n",
      "[Popularity@10] processed: 150000/190636\n",
      "[Popularity@10] processed: 152000/190636\n",
      "[Popularity@10] processed: 154000/190636\n",
      "[Popularity@10] processed: 156000/190636\n",
      "[Popularity@10] processed: 158000/190636\n",
      "[Popularity@10] processed: 160000/190636\n",
      "[Popularity@10] processed: 162000/190636\n",
      "[Popularity@10] processed: 164000/190636\n",
      "[Popularity@10] processed: 166000/190636\n",
      "[Popularity@10] processed: 168000/190636\n",
      "[Popularity@10] processed: 170000/190636\n",
      "[Popularity@10] processed: 172000/190636\n",
      "[Popularity@10] processed: 174000/190636\n",
      "[Popularity@10] processed: 176000/190636\n",
      "[Popularity@10] processed: 178000/190636\n",
      "[Popularity@10] processed: 180000/190636\n",
      "[Popularity@10] processed: 182000/190636\n",
      "[Popularity@10] processed: 184000/190636\n",
      "[Popularity@10] processed: 186000/190636\n",
      "[Popularity@10] processed: 188000/190636\n",
      "[Popularity@10] processed: 190000/190636\n",
      "[Popularity@10] processed: 190636/190636\n",
      "[ItemCosine-RAW@10] processed: 500/190636\n",
      "[ItemCosine-RAW@10] processed: 1000/190636\n",
      "[ItemCosine-RAW@10] processed: 1500/190636\n",
      "[ItemCosine-RAW@10] processed: 2000/190636\n",
      "[ItemCosine-RAW@10] processed: 2500/190636\n",
      "[ItemCosine-RAW@10] processed: 3000/190636\n",
      "[ItemCosine-RAW@10] processed: 3500/190636\n",
      "[ItemCosine-RAW@10] processed: 4000/190636\n",
      "[ItemCosine-RAW@10] processed: 4500/190636\n",
      "[ItemCosine-RAW@10] processed: 5000/190636\n",
      "[ItemCosine-RAW@10] processed: 5500/190636\n",
      "[ItemCosine-RAW@10] processed: 6000/190636\n",
      "[ItemCosine-RAW@10] processed: 6500/190636\n",
      "[ItemCosine-RAW@10] processed: 7000/190636\n",
      "[ItemCosine-RAW@10] processed: 7500/190636\n",
      "[ItemCosine-RAW@10] processed: 8000/190636\n",
      "[ItemCosine-RAW@10] processed: 8500/190636\n",
      "[ItemCosine-RAW@10] processed: 9000/190636\n",
      "[ItemCosine-RAW@10] processed: 9500/190636\n",
      "[ItemCosine-RAW@10] processed: 10000/190636\n",
      "[ItemCosine-RAW@10] processed: 10500/190636\n",
      "[ItemCosine-RAW@10] processed: 11000/190636\n",
      "[ItemCosine-RAW@10] processed: 11500/190636\n",
      "[ItemCosine-RAW@10] processed: 12000/190636\n",
      "[ItemCosine-RAW@10] processed: 12500/190636\n",
      "[ItemCosine-RAW@10] processed: 13000/190636\n",
      "[ItemCosine-RAW@10] processed: 13500/190636\n",
      "[ItemCosine-RAW@10] processed: 14000/190636\n",
      "[ItemCosine-RAW@10] processed: 14500/190636\n",
      "[ItemCosine-RAW@10] processed: 15000/190636\n",
      "[ItemCosine-RAW@10] processed: 15500/190636\n",
      "[ItemCosine-RAW@10] processed: 16000/190636\n",
      "[ItemCosine-RAW@10] processed: 16500/190636\n",
      "[ItemCosine-RAW@10] processed: 17000/190636\n",
      "[ItemCosine-RAW@10] processed: 17500/190636\n",
      "[ItemCosine-RAW@10] processed: 18000/190636\n",
      "[ItemCosine-RAW@10] processed: 18500/190636\n",
      "[ItemCosine-RAW@10] processed: 19000/190636\n",
      "[ItemCosine-RAW@10] processed: 19500/190636\n",
      "[ItemCosine-RAW@10] processed: 20000/190636\n",
      "[ItemCosine-RAW@10] processed: 20500/190636\n",
      "[ItemCosine-RAW@10] processed: 21000/190636\n",
      "[ItemCosine-RAW@10] processed: 21500/190636\n",
      "[ItemCosine-RAW@10] processed: 22000/190636\n",
      "[ItemCosine-RAW@10] processed: 22500/190636\n",
      "[ItemCosine-RAW@10] processed: 23000/190636\n",
      "[ItemCosine-RAW@10] processed: 23500/190636\n",
      "[ItemCosine-RAW@10] processed: 24000/190636\n",
      "[ItemCosine-RAW@10] processed: 24500/190636\n",
      "[ItemCosine-RAW@10] processed: 25000/190636\n",
      "[ItemCosine-RAW@10] processed: 25500/190636\n",
      "[ItemCosine-RAW@10] processed: 26000/190636\n",
      "[ItemCosine-RAW@10] processed: 26500/190636\n",
      "[ItemCosine-RAW@10] processed: 27000/190636\n",
      "[ItemCosine-RAW@10] processed: 27500/190636\n",
      "[ItemCosine-RAW@10] processed: 28000/190636\n",
      "[ItemCosine-RAW@10] processed: 28500/190636\n",
      "[ItemCosine-RAW@10] processed: 29000/190636\n",
      "[ItemCosine-RAW@10] processed: 29500/190636\n",
      "[ItemCosine-RAW@10] processed: 30000/190636\n",
      "[ItemCosine-RAW@10] processed: 30500/190636\n",
      "[ItemCosine-RAW@10] processed: 31000/190636\n",
      "[ItemCosine-RAW@10] processed: 31500/190636\n",
      "[ItemCosine-RAW@10] processed: 32000/190636\n",
      "[ItemCosine-RAW@10] processed: 32500/190636\n",
      "[ItemCosine-RAW@10] processed: 33000/190636\n",
      "[ItemCosine-RAW@10] processed: 33500/190636\n",
      "[ItemCosine-RAW@10] processed: 34000/190636\n",
      "[ItemCosine-RAW@10] processed: 34500/190636\n",
      "[ItemCosine-RAW@10] processed: 35000/190636\n",
      "[ItemCosine-RAW@10] processed: 35500/190636\n",
      "[ItemCosine-RAW@10] processed: 36000/190636\n",
      "[ItemCosine-RAW@10] processed: 36500/190636\n",
      "[ItemCosine-RAW@10] processed: 37000/190636\n",
      "[ItemCosine-RAW@10] processed: 37500/190636\n",
      "[ItemCosine-RAW@10] processed: 38000/190636\n",
      "[ItemCosine-RAW@10] processed: 38500/190636\n",
      "[ItemCosine-RAW@10] processed: 39000/190636\n",
      "[ItemCosine-RAW@10] processed: 39500/190636\n",
      "[ItemCosine-RAW@10] processed: 40000/190636\n",
      "[ItemCosine-RAW@10] processed: 40500/190636\n",
      "[ItemCosine-RAW@10] processed: 41000/190636\n",
      "[ItemCosine-RAW@10] processed: 41500/190636\n",
      "[ItemCosine-RAW@10] processed: 42000/190636\n",
      "[ItemCosine-RAW@10] processed: 42500/190636\n",
      "[ItemCosine-RAW@10] processed: 43000/190636\n",
      "[ItemCosine-RAW@10] processed: 43500/190636\n",
      "[ItemCosine-RAW@10] processed: 44000/190636\n",
      "[ItemCosine-RAW@10] processed: 44500/190636\n",
      "[ItemCosine-RAW@10] processed: 45000/190636\n",
      "[ItemCosine-RAW@10] processed: 45500/190636\n",
      "[ItemCosine-RAW@10] processed: 46000/190636\n",
      "[ItemCosine-RAW@10] processed: 46500/190636\n",
      "[ItemCosine-RAW@10] processed: 47000/190636\n",
      "[ItemCosine-RAW@10] processed: 47500/190636\n",
      "[ItemCosine-RAW@10] processed: 48000/190636\n",
      "[ItemCosine-RAW@10] processed: 48500/190636\n",
      "[ItemCosine-RAW@10] processed: 49000/190636\n",
      "[ItemCosine-RAW@10] processed: 49500/190636\n",
      "[ItemCosine-RAW@10] processed: 50000/190636\n",
      "[ItemCosine-RAW@10] processed: 50500/190636\n",
      "[ItemCosine-RAW@10] processed: 51000/190636\n",
      "[ItemCosine-RAW@10] processed: 51500/190636\n",
      "[ItemCosine-RAW@10] processed: 52000/190636\n",
      "[ItemCosine-RAW@10] processed: 52500/190636\n",
      "[ItemCosine-RAW@10] processed: 53000/190636\n",
      "[ItemCosine-RAW@10] processed: 53500/190636\n",
      "[ItemCosine-RAW@10] processed: 54000/190636\n",
      "[ItemCosine-RAW@10] processed: 54500/190636\n",
      "[ItemCosine-RAW@10] processed: 55000/190636\n",
      "[ItemCosine-RAW@10] processed: 55500/190636\n",
      "[ItemCosine-RAW@10] processed: 56000/190636\n",
      "[ItemCosine-RAW@10] processed: 56500/190636\n",
      "[ItemCosine-RAW@10] processed: 57000/190636\n",
      "[ItemCosine-RAW@10] processed: 57500/190636\n",
      "[ItemCosine-RAW@10] processed: 58000/190636\n",
      "[ItemCosine-RAW@10] processed: 58500/190636\n",
      "[ItemCosine-RAW@10] processed: 59000/190636\n",
      "[ItemCosine-RAW@10] processed: 59500/190636\n",
      "[ItemCosine-RAW@10] processed: 60000/190636\n",
      "[ItemCosine-RAW@10] processed: 60500/190636\n",
      "[ItemCosine-RAW@10] processed: 61000/190636\n",
      "[ItemCosine-RAW@10] processed: 61500/190636\n",
      "[ItemCosine-RAW@10] processed: 62000/190636\n",
      "[ItemCosine-RAW@10] processed: 62500/190636\n",
      "[ItemCosine-RAW@10] processed: 63000/190636\n",
      "[ItemCosine-RAW@10] processed: 63500/190636\n",
      "[ItemCosine-RAW@10] processed: 64000/190636\n",
      "[ItemCosine-RAW@10] processed: 64500/190636\n",
      "[ItemCosine-RAW@10] processed: 65000/190636\n",
      "[ItemCosine-RAW@10] processed: 65500/190636\n",
      "[ItemCosine-RAW@10] processed: 66000/190636\n",
      "[ItemCosine-RAW@10] processed: 66500/190636\n",
      "[ItemCosine-RAW@10] processed: 67000/190636\n",
      "[ItemCosine-RAW@10] processed: 67500/190636\n",
      "[ItemCosine-RAW@10] processed: 68000/190636\n",
      "[ItemCosine-RAW@10] processed: 68500/190636\n",
      "[ItemCosine-RAW@10] processed: 69000/190636\n",
      "[ItemCosine-RAW@10] processed: 69500/190636\n",
      "[ItemCosine-RAW@10] processed: 70000/190636\n",
      "[ItemCosine-RAW@10] processed: 70500/190636\n",
      "[ItemCosine-RAW@10] processed: 71000/190636\n",
      "[ItemCosine-RAW@10] processed: 71500/190636\n",
      "[ItemCosine-RAW@10] processed: 72000/190636\n",
      "[ItemCosine-RAW@10] processed: 72500/190636\n",
      "[ItemCosine-RAW@10] processed: 73000/190636\n",
      "[ItemCosine-RAW@10] processed: 73500/190636\n",
      "[ItemCosine-RAW@10] processed: 74000/190636\n",
      "[ItemCosine-RAW@10] processed: 74500/190636\n",
      "[ItemCosine-RAW@10] processed: 75000/190636\n",
      "[ItemCosine-RAW@10] processed: 75500/190636\n",
      "[ItemCosine-RAW@10] processed: 76000/190636\n",
      "[ItemCosine-RAW@10] processed: 76500/190636\n",
      "[ItemCosine-RAW@10] processed: 77000/190636\n",
      "[ItemCosine-RAW@10] processed: 77500/190636\n",
      "[ItemCosine-RAW@10] processed: 78000/190636\n",
      "[ItemCosine-RAW@10] processed: 78500/190636\n",
      "[ItemCosine-RAW@10] processed: 79000/190636\n",
      "[ItemCosine-RAW@10] processed: 79500/190636\n",
      "[ItemCosine-RAW@10] processed: 80000/190636\n",
      "[ItemCosine-RAW@10] processed: 80500/190636\n",
      "[ItemCosine-RAW@10] processed: 81000/190636\n",
      "[ItemCosine-RAW@10] processed: 81500/190636\n",
      "[ItemCosine-RAW@10] processed: 82000/190636\n",
      "[ItemCosine-RAW@10] processed: 82500/190636\n",
      "[ItemCosine-RAW@10] processed: 83000/190636\n",
      "[ItemCosine-RAW@10] processed: 83500/190636\n",
      "[ItemCosine-RAW@10] processed: 84000/190636\n",
      "[ItemCosine-RAW@10] processed: 84500/190636\n",
      "[ItemCosine-RAW@10] processed: 85000/190636\n",
      "[ItemCosine-RAW@10] processed: 85500/190636\n",
      "[ItemCosine-RAW@10] processed: 86000/190636\n",
      "[ItemCosine-RAW@10] processed: 86500/190636\n",
      "[ItemCosine-RAW@10] processed: 87000/190636\n",
      "[ItemCosine-RAW@10] processed: 87500/190636\n",
      "[ItemCosine-RAW@10] processed: 88000/190636\n",
      "[ItemCosine-RAW@10] processed: 88500/190636\n",
      "[ItemCosine-RAW@10] processed: 89000/190636\n",
      "[ItemCosine-RAW@10] processed: 89500/190636\n",
      "[ItemCosine-RAW@10] processed: 90000/190636\n",
      "[ItemCosine-RAW@10] processed: 90500/190636\n",
      "[ItemCosine-RAW@10] processed: 91000/190636\n",
      "[ItemCosine-RAW@10] processed: 91500/190636\n",
      "[ItemCosine-RAW@10] processed: 92000/190636\n",
      "[ItemCosine-RAW@10] processed: 92500/190636\n",
      "[ItemCosine-RAW@10] processed: 93000/190636\n",
      "[ItemCosine-RAW@10] processed: 93500/190636\n",
      "[ItemCosine-RAW@10] processed: 94000/190636\n",
      "[ItemCosine-RAW@10] processed: 94500/190636\n",
      "[ItemCosine-RAW@10] processed: 95000/190636\n",
      "[ItemCosine-RAW@10] processed: 95500/190636\n",
      "[ItemCosine-RAW@10] processed: 96000/190636\n",
      "[ItemCosine-RAW@10] processed: 96500/190636\n",
      "[ItemCosine-RAW@10] processed: 97000/190636\n",
      "[ItemCosine-RAW@10] processed: 97500/190636\n",
      "[ItemCosine-RAW@10] processed: 98000/190636\n",
      "[ItemCosine-RAW@10] processed: 98500/190636\n",
      "[ItemCosine-RAW@10] processed: 99000/190636\n",
      "[ItemCosine-RAW@10] processed: 99500/190636\n",
      "[ItemCosine-RAW@10] processed: 100000/190636\n",
      "[ItemCosine-RAW@10] processed: 100500/190636\n",
      "[ItemCosine-RAW@10] processed: 101000/190636\n",
      "[ItemCosine-RAW@10] processed: 101500/190636\n",
      "[ItemCosine-RAW@10] processed: 102000/190636\n",
      "[ItemCosine-RAW@10] processed: 102500/190636\n",
      "[ItemCosine-RAW@10] processed: 103000/190636\n",
      "[ItemCosine-RAW@10] processed: 103500/190636\n",
      "[ItemCosine-RAW@10] processed: 104000/190636\n",
      "[ItemCosine-RAW@10] processed: 104500/190636\n",
      "[ItemCosine-RAW@10] processed: 105000/190636\n",
      "[ItemCosine-RAW@10] processed: 105500/190636\n",
      "[ItemCosine-RAW@10] processed: 106000/190636\n",
      "[ItemCosine-RAW@10] processed: 106500/190636\n",
      "[ItemCosine-RAW@10] processed: 107000/190636\n",
      "[ItemCosine-RAW@10] processed: 107500/190636\n",
      "[ItemCosine-RAW@10] processed: 108000/190636\n",
      "[ItemCosine-RAW@10] processed: 108500/190636\n",
      "[ItemCosine-RAW@10] processed: 109000/190636\n",
      "[ItemCosine-RAW@10] processed: 109500/190636\n",
      "[ItemCosine-RAW@10] processed: 110000/190636\n",
      "[ItemCosine-RAW@10] processed: 110500/190636\n",
      "[ItemCosine-RAW@10] processed: 111000/190636\n",
      "[ItemCosine-RAW@10] processed: 111500/190636\n",
      "[ItemCosine-RAW@10] processed: 112000/190636\n",
      "[ItemCosine-RAW@10] processed: 112500/190636\n",
      "[ItemCosine-RAW@10] processed: 113000/190636\n",
      "[ItemCosine-RAW@10] processed: 113500/190636\n",
      "[ItemCosine-RAW@10] processed: 114000/190636\n",
      "[ItemCosine-RAW@10] processed: 114500/190636\n",
      "[ItemCosine-RAW@10] processed: 115000/190636\n",
      "[ItemCosine-RAW@10] processed: 115500/190636\n",
      "[ItemCosine-RAW@10] processed: 116000/190636\n",
      "[ItemCosine-RAW@10] processed: 116500/190636\n",
      "[ItemCosine-RAW@10] processed: 117000/190636\n",
      "[ItemCosine-RAW@10] processed: 117500/190636\n",
      "[ItemCosine-RAW@10] processed: 118000/190636\n",
      "[ItemCosine-RAW@10] processed: 118500/190636\n",
      "[ItemCosine-RAW@10] processed: 119000/190636\n",
      "[ItemCosine-RAW@10] processed: 119500/190636\n",
      "[ItemCosine-RAW@10] processed: 120000/190636\n",
      "[ItemCosine-RAW@10] processed: 120500/190636\n",
      "[ItemCosine-RAW@10] processed: 121000/190636\n",
      "[ItemCosine-RAW@10] processed: 121500/190636\n",
      "[ItemCosine-RAW@10] processed: 122000/190636\n",
      "[ItemCosine-RAW@10] processed: 122500/190636\n",
      "[ItemCosine-RAW@10] processed: 123000/190636\n",
      "[ItemCosine-RAW@10] processed: 123500/190636\n",
      "[ItemCosine-RAW@10] processed: 124000/190636\n",
      "[ItemCosine-RAW@10] processed: 124500/190636\n",
      "[ItemCosine-RAW@10] processed: 125000/190636\n",
      "[ItemCosine-RAW@10] processed: 125500/190636\n",
      "[ItemCosine-RAW@10] processed: 126000/190636\n",
      "[ItemCosine-RAW@10] processed: 126500/190636\n",
      "[ItemCosine-RAW@10] processed: 127000/190636\n",
      "[ItemCosine-RAW@10] processed: 127500/190636\n",
      "[ItemCosine-RAW@10] processed: 128000/190636\n",
      "[ItemCosine-RAW@10] processed: 128500/190636\n",
      "[ItemCosine-RAW@10] processed: 129000/190636\n",
      "[ItemCosine-RAW@10] processed: 129500/190636\n",
      "[ItemCosine-RAW@10] processed: 130000/190636\n",
      "[ItemCosine-RAW@10] processed: 130500/190636\n",
      "[ItemCosine-RAW@10] processed: 131000/190636\n",
      "[ItemCosine-RAW@10] processed: 131500/190636\n",
      "[ItemCosine-RAW@10] processed: 132000/190636\n",
      "[ItemCosine-RAW@10] processed: 132500/190636\n",
      "[ItemCosine-RAW@10] processed: 133000/190636\n",
      "[ItemCosine-RAW@10] processed: 133500/190636\n",
      "[ItemCosine-RAW@10] processed: 134000/190636\n",
      "[ItemCosine-RAW@10] processed: 134500/190636\n",
      "[ItemCosine-RAW@10] processed: 135000/190636\n",
      "[ItemCosine-RAW@10] processed: 135500/190636\n",
      "[ItemCosine-RAW@10] processed: 136000/190636\n",
      "[ItemCosine-RAW@10] processed: 136500/190636\n",
      "[ItemCosine-RAW@10] processed: 137000/190636\n",
      "[ItemCosine-RAW@10] processed: 137500/190636\n",
      "[ItemCosine-RAW@10] processed: 138000/190636\n",
      "[ItemCosine-RAW@10] processed: 138500/190636\n",
      "[ItemCosine-RAW@10] processed: 139000/190636\n",
      "[ItemCosine-RAW@10] processed: 139500/190636\n",
      "[ItemCosine-RAW@10] processed: 140000/190636\n",
      "[ItemCosine-RAW@10] processed: 140500/190636\n",
      "[ItemCosine-RAW@10] processed: 141000/190636\n",
      "[ItemCosine-RAW@10] processed: 141500/190636\n",
      "[ItemCosine-RAW@10] processed: 142000/190636\n",
      "[ItemCosine-RAW@10] processed: 142500/190636\n",
      "[ItemCosine-RAW@10] processed: 143000/190636\n",
      "[ItemCosine-RAW@10] processed: 143500/190636\n",
      "[ItemCosine-RAW@10] processed: 144000/190636\n",
      "[ItemCosine-RAW@10] processed: 144500/190636\n",
      "[ItemCosine-RAW@10] processed: 145000/190636\n",
      "[ItemCosine-RAW@10] processed: 145500/190636\n",
      "[ItemCosine-RAW@10] processed: 146000/190636\n",
      "[ItemCosine-RAW@10] processed: 146500/190636\n",
      "[ItemCosine-RAW@10] processed: 147000/190636\n",
      "[ItemCosine-RAW@10] processed: 147500/190636\n",
      "[ItemCosine-RAW@10] processed: 148000/190636\n",
      "[ItemCosine-RAW@10] processed: 148500/190636\n",
      "[ItemCosine-RAW@10] processed: 149000/190636\n",
      "[ItemCosine-RAW@10] processed: 149500/190636\n",
      "[ItemCosine-RAW@10] processed: 150000/190636\n",
      "[ItemCosine-RAW@10] processed: 150500/190636\n",
      "[ItemCosine-RAW@10] processed: 151000/190636\n",
      "[ItemCosine-RAW@10] processed: 151500/190636\n",
      "[ItemCosine-RAW@10] processed: 152000/190636\n",
      "[ItemCosine-RAW@10] processed: 152500/190636\n",
      "[ItemCosine-RAW@10] processed: 153000/190636\n",
      "[ItemCosine-RAW@10] processed: 153500/190636\n",
      "[ItemCosine-RAW@10] processed: 154000/190636\n",
      "[ItemCosine-RAW@10] processed: 154500/190636\n",
      "[ItemCosine-RAW@10] processed: 155000/190636\n",
      "[ItemCosine-RAW@10] processed: 155500/190636\n",
      "[ItemCosine-RAW@10] processed: 156000/190636\n",
      "[ItemCosine-RAW@10] processed: 156500/190636\n",
      "[ItemCosine-RAW@10] processed: 157000/190636\n",
      "[ItemCosine-RAW@10] processed: 157500/190636\n",
      "[ItemCosine-RAW@10] processed: 158000/190636\n",
      "[ItemCosine-RAW@10] processed: 158500/190636\n",
      "[ItemCosine-RAW@10] processed: 159000/190636\n",
      "[ItemCosine-RAW@10] processed: 159500/190636\n",
      "[ItemCosine-RAW@10] processed: 160000/190636\n",
      "[ItemCosine-RAW@10] processed: 160500/190636\n",
      "[ItemCosine-RAW@10] processed: 161000/190636\n",
      "[ItemCosine-RAW@10] processed: 161500/190636\n",
      "[ItemCosine-RAW@10] processed: 162000/190636\n",
      "[ItemCosine-RAW@10] processed: 162500/190636\n",
      "[ItemCosine-RAW@10] processed: 163000/190636\n",
      "[ItemCosine-RAW@10] processed: 163500/190636\n",
      "[ItemCosine-RAW@10] processed: 164000/190636\n",
      "[ItemCosine-RAW@10] processed: 164500/190636\n",
      "[ItemCosine-RAW@10] processed: 165000/190636\n",
      "[ItemCosine-RAW@10] processed: 165500/190636\n",
      "[ItemCosine-RAW@10] processed: 166000/190636\n",
      "[ItemCosine-RAW@10] processed: 166500/190636\n",
      "[ItemCosine-RAW@10] processed: 167000/190636\n",
      "[ItemCosine-RAW@10] processed: 167500/190636\n",
      "[ItemCosine-RAW@10] processed: 168000/190636\n",
      "[ItemCosine-RAW@10] processed: 168500/190636\n",
      "[ItemCosine-RAW@10] processed: 169000/190636\n",
      "[ItemCosine-RAW@10] processed: 169500/190636\n",
      "[ItemCosine-RAW@10] processed: 170000/190636\n",
      "[ItemCosine-RAW@10] processed: 170500/190636\n",
      "[ItemCosine-RAW@10] processed: 171000/190636\n",
      "[ItemCosine-RAW@10] processed: 171500/190636\n",
      "[ItemCosine-RAW@10] processed: 172000/190636\n",
      "[ItemCosine-RAW@10] processed: 172500/190636\n",
      "[ItemCosine-RAW@10] processed: 173000/190636\n",
      "[ItemCosine-RAW@10] processed: 173500/190636\n",
      "[ItemCosine-RAW@10] processed: 174000/190636\n",
      "[ItemCosine-RAW@10] processed: 174500/190636\n",
      "[ItemCosine-RAW@10] processed: 175000/190636\n",
      "[ItemCosine-RAW@10] processed: 175500/190636\n",
      "[ItemCosine-RAW@10] processed: 176000/190636\n",
      "[ItemCosine-RAW@10] processed: 176500/190636\n",
      "[ItemCosine-RAW@10] processed: 177000/190636\n",
      "[ItemCosine-RAW@10] processed: 177500/190636\n",
      "[ItemCosine-RAW@10] processed: 178000/190636\n",
      "[ItemCosine-RAW@10] processed: 178500/190636\n",
      "[ItemCosine-RAW@10] processed: 179000/190636\n",
      "[ItemCosine-RAW@10] processed: 179500/190636\n",
      "[ItemCosine-RAW@10] processed: 180000/190636\n",
      "[ItemCosine-RAW@10] processed: 180500/190636\n",
      "[ItemCosine-RAW@10] processed: 181000/190636\n",
      "[ItemCosine-RAW@10] processed: 181500/190636\n",
      "[ItemCosine-RAW@10] processed: 182000/190636\n",
      "[ItemCosine-RAW@10] processed: 182500/190636\n",
      "[ItemCosine-RAW@10] processed: 183000/190636\n",
      "[ItemCosine-RAW@10] processed: 183500/190636\n",
      "[ItemCosine-RAW@10] processed: 184000/190636\n",
      "[ItemCosine-RAW@10] processed: 184500/190636\n",
      "[ItemCosine-RAW@10] processed: 185000/190636\n",
      "[ItemCosine-RAW@10] processed: 185500/190636\n",
      "[ItemCosine-RAW@10] processed: 186000/190636\n",
      "[ItemCosine-RAW@10] processed: 186500/190636\n",
      "[ItemCosine-RAW@10] processed: 187000/190636\n",
      "[ItemCosine-RAW@10] processed: 187500/190636\n",
      "[ItemCosine-RAW@10] processed: 188000/190636\n",
      "[ItemCosine-RAW@10] processed: 188500/190636\n",
      "[ItemCosine-RAW@10] processed: 189000/190636\n",
      "[ItemCosine-RAW@10] processed: 189500/190636\n",
      "[ItemCosine-RAW@10] processed: 190000/190636\n",
      "[ItemCosine-RAW@10] processed: 190500/190636\n",
      "[ItemCosine-RAW@10] processed: 190636/190636\n",
      "[ItemCosine-TFIDF@10] processed: 500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 1000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 1500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 2000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 2500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 3000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 3500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 4000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 4500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 5000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 5500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 6000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 6500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 7000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 7500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 8000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 8500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 9000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 9500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 10000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 10500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 11000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 11500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 12000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 12500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 13000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 13500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 14000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 14500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 15000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 15500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 16000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 16500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 17000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 17500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 18000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 18500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 19000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 19500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 20000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 20500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 21000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 21500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 22000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 22500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 23000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 23500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 24000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 24500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 25000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 25500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 26000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 26500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 27000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 27500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 28000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 28500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 29000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 29500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 30000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 30500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 31000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 31500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 32000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 32500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 33000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 33500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 34000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 34500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 35000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 35500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 36000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 36500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 37000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 37500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 38000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 38500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 39000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 39500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 40000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 40500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 41000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 41500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 42000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 42500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 43000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 43500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 44000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 44500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 45000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 45500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 46000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 46500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 47000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 47500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 48000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 48500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 49000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 49500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 50000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 50500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 51000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 51500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 52000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 52500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 53000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 53500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 54000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 54500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 55000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 55500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 56000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 56500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 57000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 57500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 58000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 58500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 59000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 59500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 60000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 60500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 61000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 61500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 62000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 62500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 63000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 63500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 64000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 64500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 65000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 65500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 66000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 66500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 67000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 67500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 68000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 68500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 69000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 69500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 70000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 70500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 71000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 71500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 72000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 72500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 73000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 73500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 74000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 74500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 75000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 75500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 76000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 76500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 77000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 77500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 78000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 78500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 79000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 79500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 80000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 80500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 81000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 81500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 82000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 82500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 83000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 83500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 84000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 84500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 85000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 85500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 86000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 86500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 87000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 87500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 88000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 88500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 89000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 89500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 90000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 90500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 91000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 91500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 92000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 92500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 93000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 93500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 94000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 94500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 95000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 95500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 96000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 96500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 97000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 97500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 98000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 98500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 99000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 99500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 100000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 100500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 101000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 101500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 102000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 102500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 103000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 103500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 104000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 104500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 105000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 105500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 106000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 106500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 107000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 107500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 108000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 108500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 109000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 109500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 110000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 110500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 111000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 111500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 112000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 112500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 113000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 113500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 114000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 114500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 115000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 115500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 116000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 116500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 117000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 117500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 118000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 118500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 119000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 119500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 120000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 120500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 121000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 121500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 122000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 122500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 123000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 123500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 124000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 124500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 125000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 125500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 126000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 126500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 127000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 127500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 128000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 128500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 129000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 129500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 130000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 130500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 131000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 131500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 132000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 132500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 133000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 133500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 134000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 134500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 135000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 135500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 136000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 136500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 137000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 137500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 138000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 138500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 139000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 139500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 140000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 140500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 141000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 141500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 142000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 142500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 143000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 143500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 144000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 144500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 145000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 145500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 146000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 146500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 147000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 147500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 148000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 148500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 149000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 149500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 150000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 150500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 151000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 151500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 152000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 152500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 153000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 153500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 154000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 154500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 155000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 155500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 156000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 156500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 157000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 157500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 158000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 158500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 159000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 159500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 160000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 160500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 161000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 161500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 162000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 162500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 163000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 163500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 164000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 164500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 165000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 165500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 166000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 166500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 167000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 167500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 168000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 168500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 169000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 169500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 170000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 170500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 171000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 171500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 172000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 172500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 173000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 173500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 174000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 174500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 175000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 175500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 176000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 176500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 177000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 177500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 178000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 178500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 179000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 179500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 180000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 180500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 181000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 181500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 182000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 182500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 183000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 183500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 184000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 184500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 185000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 185500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 186000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 186500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 187000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 187500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 188000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 188500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 189000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 189500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 190000/190636\n",
      "[ItemCosine-TFIDF@10] processed: 190500/190636\n",
      "[ItemCosine-TFIDF@10] processed: 190636/190636\n",
      "[ItemCosine-BM25@10] processed: 500/190636\n",
      "[ItemCosine-BM25@10] processed: 1000/190636\n",
      "[ItemCosine-BM25@10] processed: 1500/190636\n",
      "[ItemCosine-BM25@10] processed: 2000/190636\n",
      "[ItemCosine-BM25@10] processed: 2500/190636\n",
      "[ItemCosine-BM25@10] processed: 3000/190636\n",
      "[ItemCosine-BM25@10] processed: 3500/190636\n",
      "[ItemCosine-BM25@10] processed: 4000/190636\n",
      "[ItemCosine-BM25@10] processed: 4500/190636\n",
      "[ItemCosine-BM25@10] processed: 5000/190636\n",
      "[ItemCosine-BM25@10] processed: 5500/190636\n",
      "[ItemCosine-BM25@10] processed: 6000/190636\n",
      "[ItemCosine-BM25@10] processed: 6500/190636\n",
      "[ItemCosine-BM25@10] processed: 7000/190636\n",
      "[ItemCosine-BM25@10] processed: 7500/190636\n",
      "[ItemCosine-BM25@10] processed: 8000/190636\n",
      "[ItemCosine-BM25@10] processed: 8500/190636\n",
      "[ItemCosine-BM25@10] processed: 9000/190636\n",
      "[ItemCosine-BM25@10] processed: 9500/190636\n",
      "[ItemCosine-BM25@10] processed: 10000/190636\n",
      "[ItemCosine-BM25@10] processed: 10500/190636\n",
      "[ItemCosine-BM25@10] processed: 11000/190636\n",
      "[ItemCosine-BM25@10] processed: 11500/190636\n",
      "[ItemCosine-BM25@10] processed: 12000/190636\n",
      "[ItemCosine-BM25@10] processed: 12500/190636\n",
      "[ItemCosine-BM25@10] processed: 13000/190636\n",
      "[ItemCosine-BM25@10] processed: 13500/190636\n",
      "[ItemCosine-BM25@10] processed: 14000/190636\n",
      "[ItemCosine-BM25@10] processed: 14500/190636\n",
      "[ItemCosine-BM25@10] processed: 15000/190636\n",
      "[ItemCosine-BM25@10] processed: 15500/190636\n",
      "[ItemCosine-BM25@10] processed: 16000/190636\n",
      "[ItemCosine-BM25@10] processed: 16500/190636\n",
      "[ItemCosine-BM25@10] processed: 17000/190636\n",
      "[ItemCosine-BM25@10] processed: 17500/190636\n",
      "[ItemCosine-BM25@10] processed: 18000/190636\n",
      "[ItemCosine-BM25@10] processed: 18500/190636\n",
      "[ItemCosine-BM25@10] processed: 19000/190636\n",
      "[ItemCosine-BM25@10] processed: 19500/190636\n",
      "[ItemCosine-BM25@10] processed: 20000/190636\n",
      "[ItemCosine-BM25@10] processed: 20500/190636\n",
      "[ItemCosine-BM25@10] processed: 21000/190636\n",
      "[ItemCosine-BM25@10] processed: 21500/190636\n",
      "[ItemCosine-BM25@10] processed: 22000/190636\n",
      "[ItemCosine-BM25@10] processed: 22500/190636\n",
      "[ItemCosine-BM25@10] processed: 23000/190636\n",
      "[ItemCosine-BM25@10] processed: 23500/190636\n",
      "[ItemCosine-BM25@10] processed: 24000/190636\n",
      "[ItemCosine-BM25@10] processed: 24500/190636\n",
      "[ItemCosine-BM25@10] processed: 25000/190636\n",
      "[ItemCosine-BM25@10] processed: 25500/190636\n",
      "[ItemCosine-BM25@10] processed: 26000/190636\n",
      "[ItemCosine-BM25@10] processed: 26500/190636\n",
      "[ItemCosine-BM25@10] processed: 27000/190636\n",
      "[ItemCosine-BM25@10] processed: 27500/190636\n",
      "[ItemCosine-BM25@10] processed: 28000/190636\n",
      "[ItemCosine-BM25@10] processed: 28500/190636\n",
      "[ItemCosine-BM25@10] processed: 29000/190636\n",
      "[ItemCosine-BM25@10] processed: 29500/190636\n",
      "[ItemCosine-BM25@10] processed: 30000/190636\n",
      "[ItemCosine-BM25@10] processed: 30500/190636\n",
      "[ItemCosine-BM25@10] processed: 31000/190636\n",
      "[ItemCosine-BM25@10] processed: 31500/190636\n",
      "[ItemCosine-BM25@10] processed: 32000/190636\n",
      "[ItemCosine-BM25@10] processed: 32500/190636\n",
      "[ItemCosine-BM25@10] processed: 33000/190636\n",
      "[ItemCosine-BM25@10] processed: 33500/190636\n",
      "[ItemCosine-BM25@10] processed: 34000/190636\n",
      "[ItemCosine-BM25@10] processed: 34500/190636\n",
      "[ItemCosine-BM25@10] processed: 35000/190636\n",
      "[ItemCosine-BM25@10] processed: 35500/190636\n",
      "[ItemCosine-BM25@10] processed: 36000/190636\n",
      "[ItemCosine-BM25@10] processed: 36500/190636\n",
      "[ItemCosine-BM25@10] processed: 37000/190636\n",
      "[ItemCosine-BM25@10] processed: 37500/190636\n",
      "[ItemCosine-BM25@10] processed: 38000/190636\n",
      "[ItemCosine-BM25@10] processed: 38500/190636\n",
      "[ItemCosine-BM25@10] processed: 39000/190636\n",
      "[ItemCosine-BM25@10] processed: 39500/190636\n",
      "[ItemCosine-BM25@10] processed: 40000/190636\n",
      "[ItemCosine-BM25@10] processed: 40500/190636\n",
      "[ItemCosine-BM25@10] processed: 41000/190636\n",
      "[ItemCosine-BM25@10] processed: 41500/190636\n",
      "[ItemCosine-BM25@10] processed: 42000/190636\n",
      "[ItemCosine-BM25@10] processed: 42500/190636\n",
      "[ItemCosine-BM25@10] processed: 43000/190636\n",
      "[ItemCosine-BM25@10] processed: 43500/190636\n",
      "[ItemCosine-BM25@10] processed: 44000/190636\n",
      "[ItemCosine-BM25@10] processed: 44500/190636\n",
      "[ItemCosine-BM25@10] processed: 45000/190636\n",
      "[ItemCosine-BM25@10] processed: 45500/190636\n",
      "[ItemCosine-BM25@10] processed: 46000/190636\n",
      "[ItemCosine-BM25@10] processed: 46500/190636\n",
      "[ItemCosine-BM25@10] processed: 47000/190636\n",
      "[ItemCosine-BM25@10] processed: 47500/190636\n",
      "[ItemCosine-BM25@10] processed: 48000/190636\n",
      "[ItemCosine-BM25@10] processed: 48500/190636\n",
      "[ItemCosine-BM25@10] processed: 49000/190636\n",
      "[ItemCosine-BM25@10] processed: 49500/190636\n",
      "[ItemCosine-BM25@10] processed: 50000/190636\n",
      "[ItemCosine-BM25@10] processed: 50500/190636\n",
      "[ItemCosine-BM25@10] processed: 51000/190636\n",
      "[ItemCosine-BM25@10] processed: 51500/190636\n",
      "[ItemCosine-BM25@10] processed: 52000/190636\n",
      "[ItemCosine-BM25@10] processed: 52500/190636\n",
      "[ItemCosine-BM25@10] processed: 53000/190636\n",
      "[ItemCosine-BM25@10] processed: 53500/190636\n",
      "[ItemCosine-BM25@10] processed: 54000/190636\n",
      "[ItemCosine-BM25@10] processed: 54500/190636\n",
      "[ItemCosine-BM25@10] processed: 55000/190636\n",
      "[ItemCosine-BM25@10] processed: 55500/190636\n",
      "[ItemCosine-BM25@10] processed: 56000/190636\n",
      "[ItemCosine-BM25@10] processed: 56500/190636\n",
      "[ItemCosine-BM25@10] processed: 57000/190636\n",
      "[ItemCosine-BM25@10] processed: 57500/190636\n",
      "[ItemCosine-BM25@10] processed: 58000/190636\n",
      "[ItemCosine-BM25@10] processed: 58500/190636\n",
      "[ItemCosine-BM25@10] processed: 59000/190636\n",
      "[ItemCosine-BM25@10] processed: 59500/190636\n",
      "[ItemCosine-BM25@10] processed: 60000/190636\n",
      "[ItemCosine-BM25@10] processed: 60500/190636\n",
      "[ItemCosine-BM25@10] processed: 61000/190636\n",
      "[ItemCosine-BM25@10] processed: 61500/190636\n",
      "[ItemCosine-BM25@10] processed: 62000/190636\n",
      "[ItemCosine-BM25@10] processed: 62500/190636\n",
      "[ItemCosine-BM25@10] processed: 63000/190636\n",
      "[ItemCosine-BM25@10] processed: 63500/190636\n",
      "[ItemCosine-BM25@10] processed: 64000/190636\n",
      "[ItemCosine-BM25@10] processed: 64500/190636\n",
      "[ItemCosine-BM25@10] processed: 65000/190636\n",
      "[ItemCosine-BM25@10] processed: 65500/190636\n",
      "[ItemCosine-BM25@10] processed: 66000/190636\n",
      "[ItemCosine-BM25@10] processed: 66500/190636\n",
      "[ItemCosine-BM25@10] processed: 67000/190636\n",
      "[ItemCosine-BM25@10] processed: 67500/190636\n",
      "[ItemCosine-BM25@10] processed: 68000/190636\n",
      "[ItemCosine-BM25@10] processed: 68500/190636\n",
      "[ItemCosine-BM25@10] processed: 69000/190636\n",
      "[ItemCosine-BM25@10] processed: 69500/190636\n",
      "[ItemCosine-BM25@10] processed: 70000/190636\n",
      "[ItemCosine-BM25@10] processed: 70500/190636\n",
      "[ItemCosine-BM25@10] processed: 71000/190636\n",
      "[ItemCosine-BM25@10] processed: 71500/190636\n",
      "[ItemCosine-BM25@10] processed: 72000/190636\n",
      "[ItemCosine-BM25@10] processed: 72500/190636\n",
      "[ItemCosine-BM25@10] processed: 73000/190636\n",
      "[ItemCosine-BM25@10] processed: 73500/190636\n",
      "[ItemCosine-BM25@10] processed: 74000/190636\n",
      "[ItemCosine-BM25@10] processed: 74500/190636\n",
      "[ItemCosine-BM25@10] processed: 75000/190636\n",
      "[ItemCosine-BM25@10] processed: 75500/190636\n",
      "[ItemCosine-BM25@10] processed: 76000/190636\n",
      "[ItemCosine-BM25@10] processed: 76500/190636\n",
      "[ItemCosine-BM25@10] processed: 77000/190636\n",
      "[ItemCosine-BM25@10] processed: 77500/190636\n",
      "[ItemCosine-BM25@10] processed: 78000/190636\n",
      "[ItemCosine-BM25@10] processed: 78500/190636\n",
      "[ItemCosine-BM25@10] processed: 79000/190636\n",
      "[ItemCosine-BM25@10] processed: 79500/190636\n",
      "[ItemCosine-BM25@10] processed: 80000/190636\n",
      "[ItemCosine-BM25@10] processed: 80500/190636\n",
      "[ItemCosine-BM25@10] processed: 81000/190636\n",
      "[ItemCosine-BM25@10] processed: 81500/190636\n",
      "[ItemCosine-BM25@10] processed: 82000/190636\n",
      "[ItemCosine-BM25@10] processed: 82500/190636\n",
      "[ItemCosine-BM25@10] processed: 83000/190636\n",
      "[ItemCosine-BM25@10] processed: 83500/190636\n",
      "[ItemCosine-BM25@10] processed: 84000/190636\n",
      "[ItemCosine-BM25@10] processed: 84500/190636\n",
      "[ItemCosine-BM25@10] processed: 85000/190636\n",
      "[ItemCosine-BM25@10] processed: 85500/190636\n",
      "[ItemCosine-BM25@10] processed: 86000/190636\n",
      "[ItemCosine-BM25@10] processed: 86500/190636\n",
      "[ItemCosine-BM25@10] processed: 87000/190636\n",
      "[ItemCosine-BM25@10] processed: 87500/190636\n",
      "[ItemCosine-BM25@10] processed: 88000/190636\n",
      "[ItemCosine-BM25@10] processed: 88500/190636\n",
      "[ItemCosine-BM25@10] processed: 89000/190636\n",
      "[ItemCosine-BM25@10] processed: 89500/190636\n",
      "[ItemCosine-BM25@10] processed: 90000/190636\n",
      "[ItemCosine-BM25@10] processed: 90500/190636\n",
      "[ItemCosine-BM25@10] processed: 91000/190636\n",
      "[ItemCosine-BM25@10] processed: 91500/190636\n",
      "[ItemCosine-BM25@10] processed: 92000/190636\n",
      "[ItemCosine-BM25@10] processed: 92500/190636\n",
      "[ItemCosine-BM25@10] processed: 93000/190636\n",
      "[ItemCosine-BM25@10] processed: 93500/190636\n",
      "[ItemCosine-BM25@10] processed: 94000/190636\n",
      "[ItemCosine-BM25@10] processed: 94500/190636\n",
      "[ItemCosine-BM25@10] processed: 95000/190636\n",
      "[ItemCosine-BM25@10] processed: 95500/190636\n",
      "[ItemCosine-BM25@10] processed: 96000/190636\n",
      "[ItemCosine-BM25@10] processed: 96500/190636\n",
      "[ItemCosine-BM25@10] processed: 97000/190636\n",
      "[ItemCosine-BM25@10] processed: 97500/190636\n",
      "[ItemCosine-BM25@10] processed: 98000/190636\n",
      "[ItemCosine-BM25@10] processed: 98500/190636\n",
      "[ItemCosine-BM25@10] processed: 99000/190636\n",
      "[ItemCosine-BM25@10] processed: 99500/190636\n",
      "[ItemCosine-BM25@10] processed: 100000/190636\n",
      "[ItemCosine-BM25@10] processed: 100500/190636\n",
      "[ItemCosine-BM25@10] processed: 101000/190636\n",
      "[ItemCosine-BM25@10] processed: 101500/190636\n",
      "[ItemCosine-BM25@10] processed: 102000/190636\n",
      "[ItemCosine-BM25@10] processed: 102500/190636\n",
      "[ItemCosine-BM25@10] processed: 103000/190636\n",
      "[ItemCosine-BM25@10] processed: 103500/190636\n",
      "[ItemCosine-BM25@10] processed: 104000/190636\n",
      "[ItemCosine-BM25@10] processed: 104500/190636\n",
      "[ItemCosine-BM25@10] processed: 105000/190636\n",
      "[ItemCosine-BM25@10] processed: 105500/190636\n",
      "[ItemCosine-BM25@10] processed: 106000/190636\n",
      "[ItemCosine-BM25@10] processed: 106500/190636\n",
      "[ItemCosine-BM25@10] processed: 107000/190636\n",
      "[ItemCosine-BM25@10] processed: 107500/190636\n",
      "[ItemCosine-BM25@10] processed: 108000/190636\n",
      "[ItemCosine-BM25@10] processed: 108500/190636\n",
      "[ItemCosine-BM25@10] processed: 109000/190636\n",
      "[ItemCosine-BM25@10] processed: 109500/190636\n",
      "[ItemCosine-BM25@10] processed: 110000/190636\n",
      "[ItemCosine-BM25@10] processed: 110500/190636\n",
      "[ItemCosine-BM25@10] processed: 111000/190636\n",
      "[ItemCosine-BM25@10] processed: 111500/190636\n",
      "[ItemCosine-BM25@10] processed: 112000/190636\n",
      "[ItemCosine-BM25@10] processed: 112500/190636\n",
      "[ItemCosine-BM25@10] processed: 113000/190636\n",
      "[ItemCosine-BM25@10] processed: 113500/190636\n",
      "[ItemCosine-BM25@10] processed: 114000/190636\n",
      "[ItemCosine-BM25@10] processed: 114500/190636\n",
      "[ItemCosine-BM25@10] processed: 115000/190636\n",
      "[ItemCosine-BM25@10] processed: 115500/190636\n",
      "[ItemCosine-BM25@10] processed: 116000/190636\n",
      "[ItemCosine-BM25@10] processed: 116500/190636\n",
      "[ItemCosine-BM25@10] processed: 117000/190636\n",
      "[ItemCosine-BM25@10] processed: 117500/190636\n",
      "[ItemCosine-BM25@10] processed: 118000/190636\n",
      "[ItemCosine-BM25@10] processed: 118500/190636\n",
      "[ItemCosine-BM25@10] processed: 119000/190636\n",
      "[ItemCosine-BM25@10] processed: 119500/190636\n",
      "[ItemCosine-BM25@10] processed: 120000/190636\n",
      "[ItemCosine-BM25@10] processed: 120500/190636\n",
      "[ItemCosine-BM25@10] processed: 121000/190636\n",
      "[ItemCosine-BM25@10] processed: 121500/190636\n",
      "[ItemCosine-BM25@10] processed: 122000/190636\n",
      "[ItemCosine-BM25@10] processed: 122500/190636\n",
      "[ItemCosine-BM25@10] processed: 123000/190636\n",
      "[ItemCosine-BM25@10] processed: 123500/190636\n",
      "[ItemCosine-BM25@10] processed: 124000/190636\n",
      "[ItemCosine-BM25@10] processed: 124500/190636\n",
      "[ItemCosine-BM25@10] processed: 125000/190636\n",
      "[ItemCosine-BM25@10] processed: 125500/190636\n",
      "[ItemCosine-BM25@10] processed: 126000/190636\n",
      "[ItemCosine-BM25@10] processed: 126500/190636\n",
      "[ItemCosine-BM25@10] processed: 127000/190636\n",
      "[ItemCosine-BM25@10] processed: 127500/190636\n",
      "[ItemCosine-BM25@10] processed: 128000/190636\n",
      "[ItemCosine-BM25@10] processed: 128500/190636\n",
      "[ItemCosine-BM25@10] processed: 129000/190636\n",
      "[ItemCosine-BM25@10] processed: 129500/190636\n",
      "[ItemCosine-BM25@10] processed: 130000/190636\n",
      "[ItemCosine-BM25@10] processed: 130500/190636\n",
      "[ItemCosine-BM25@10] processed: 131000/190636\n",
      "[ItemCosine-BM25@10] processed: 131500/190636\n",
      "[ItemCosine-BM25@10] processed: 132000/190636\n",
      "[ItemCosine-BM25@10] processed: 132500/190636\n",
      "[ItemCosine-BM25@10] processed: 133000/190636\n",
      "[ItemCosine-BM25@10] processed: 133500/190636\n",
      "[ItemCosine-BM25@10] processed: 134000/190636\n",
      "[ItemCosine-BM25@10] processed: 134500/190636\n",
      "[ItemCosine-BM25@10] processed: 135000/190636\n",
      "[ItemCosine-BM25@10] processed: 135500/190636\n",
      "[ItemCosine-BM25@10] processed: 136000/190636\n",
      "[ItemCosine-BM25@10] processed: 136500/190636\n",
      "[ItemCosine-BM25@10] processed: 137000/190636\n",
      "[ItemCosine-BM25@10] processed: 137500/190636\n",
      "[ItemCosine-BM25@10] processed: 138000/190636\n",
      "[ItemCosine-BM25@10] processed: 138500/190636\n",
      "[ItemCosine-BM25@10] processed: 139000/190636\n",
      "[ItemCosine-BM25@10] processed: 139500/190636\n",
      "[ItemCosine-BM25@10] processed: 140000/190636\n",
      "[ItemCosine-BM25@10] processed: 140500/190636\n",
      "[ItemCosine-BM25@10] processed: 141000/190636\n",
      "[ItemCosine-BM25@10] processed: 141500/190636\n",
      "[ItemCosine-BM25@10] processed: 142000/190636\n",
      "[ItemCosine-BM25@10] processed: 142500/190636\n",
      "[ItemCosine-BM25@10] processed: 143000/190636\n",
      "[ItemCosine-BM25@10] processed: 143500/190636\n",
      "[ItemCosine-BM25@10] processed: 144000/190636\n",
      "[ItemCosine-BM25@10] processed: 144500/190636\n",
      "[ItemCosine-BM25@10] processed: 145000/190636\n",
      "[ItemCosine-BM25@10] processed: 145500/190636\n",
      "[ItemCosine-BM25@10] processed: 146000/190636\n",
      "[ItemCosine-BM25@10] processed: 146500/190636\n",
      "[ItemCosine-BM25@10] processed: 147000/190636\n",
      "[ItemCosine-BM25@10] processed: 147500/190636\n",
      "[ItemCosine-BM25@10] processed: 148000/190636\n",
      "[ItemCosine-BM25@10] processed: 148500/190636\n",
      "[ItemCosine-BM25@10] processed: 149000/190636\n",
      "[ItemCosine-BM25@10] processed: 149500/190636\n",
      "[ItemCosine-BM25@10] processed: 150000/190636\n",
      "[ItemCosine-BM25@10] processed: 150500/190636\n",
      "[ItemCosine-BM25@10] processed: 151000/190636\n",
      "[ItemCosine-BM25@10] processed: 151500/190636\n",
      "[ItemCosine-BM25@10] processed: 152000/190636\n",
      "[ItemCosine-BM25@10] processed: 152500/190636\n",
      "[ItemCosine-BM25@10] processed: 153000/190636\n",
      "[ItemCosine-BM25@10] processed: 153500/190636\n",
      "[ItemCosine-BM25@10] processed: 154000/190636\n",
      "[ItemCosine-BM25@10] processed: 154500/190636\n",
      "[ItemCosine-BM25@10] processed: 155000/190636\n",
      "[ItemCosine-BM25@10] processed: 155500/190636\n",
      "[ItemCosine-BM25@10] processed: 156000/190636\n",
      "[ItemCosine-BM25@10] processed: 156500/190636\n",
      "[ItemCosine-BM25@10] processed: 157000/190636\n",
      "[ItemCosine-BM25@10] processed: 157500/190636\n",
      "[ItemCosine-BM25@10] processed: 158000/190636\n",
      "[ItemCosine-BM25@10] processed: 158500/190636\n",
      "[ItemCosine-BM25@10] processed: 159000/190636\n",
      "[ItemCosine-BM25@10] processed: 159500/190636\n",
      "[ItemCosine-BM25@10] processed: 160000/190636\n",
      "[ItemCosine-BM25@10] processed: 160500/190636\n",
      "[ItemCosine-BM25@10] processed: 161000/190636\n",
      "[ItemCosine-BM25@10] processed: 161500/190636\n",
      "[ItemCosine-BM25@10] processed: 162000/190636\n",
      "[ItemCosine-BM25@10] processed: 162500/190636\n",
      "[ItemCosine-BM25@10] processed: 163000/190636\n",
      "[ItemCosine-BM25@10] processed: 163500/190636\n",
      "[ItemCosine-BM25@10] processed: 164000/190636\n",
      "[ItemCosine-BM25@10] processed: 164500/190636\n",
      "[ItemCosine-BM25@10] processed: 165000/190636\n",
      "[ItemCosine-BM25@10] processed: 165500/190636\n",
      "[ItemCosine-BM25@10] processed: 166000/190636\n",
      "[ItemCosine-BM25@10] processed: 166500/190636\n",
      "[ItemCosine-BM25@10] processed: 167000/190636\n",
      "[ItemCosine-BM25@10] processed: 167500/190636\n",
      "[ItemCosine-BM25@10] processed: 168000/190636\n",
      "[ItemCosine-BM25@10] processed: 168500/190636\n",
      "[ItemCosine-BM25@10] processed: 169000/190636\n",
      "[ItemCosine-BM25@10] processed: 169500/190636\n",
      "[ItemCosine-BM25@10] processed: 170000/190636\n",
      "[ItemCosine-BM25@10] processed: 170500/190636\n",
      "[ItemCosine-BM25@10] processed: 171000/190636\n",
      "[ItemCosine-BM25@10] processed: 171500/190636\n",
      "[ItemCosine-BM25@10] processed: 172000/190636\n",
      "[ItemCosine-BM25@10] processed: 172500/190636\n",
      "[ItemCosine-BM25@10] processed: 173000/190636\n",
      "[ItemCosine-BM25@10] processed: 173500/190636\n",
      "[ItemCosine-BM25@10] processed: 174000/190636\n",
      "[ItemCosine-BM25@10] processed: 174500/190636\n",
      "[ItemCosine-BM25@10] processed: 175000/190636\n",
      "[ItemCosine-BM25@10] processed: 175500/190636\n",
      "[ItemCosine-BM25@10] processed: 176000/190636\n",
      "[ItemCosine-BM25@10] processed: 176500/190636\n",
      "[ItemCosine-BM25@10] processed: 177000/190636\n",
      "[ItemCosine-BM25@10] processed: 177500/190636\n",
      "[ItemCosine-BM25@10] processed: 178000/190636\n",
      "[ItemCosine-BM25@10] processed: 178500/190636\n",
      "[ItemCosine-BM25@10] processed: 179000/190636\n",
      "[ItemCosine-BM25@10] processed: 179500/190636\n",
      "[ItemCosine-BM25@10] processed: 180000/190636\n",
      "[ItemCosine-BM25@10] processed: 180500/190636\n",
      "[ItemCosine-BM25@10] processed: 181000/190636\n",
      "[ItemCosine-BM25@10] processed: 181500/190636\n",
      "[ItemCosine-BM25@10] processed: 182000/190636\n",
      "[ItemCosine-BM25@10] processed: 182500/190636\n",
      "[ItemCosine-BM25@10] processed: 183000/190636\n",
      "[ItemCosine-BM25@10] processed: 183500/190636\n",
      "[ItemCosine-BM25@10] processed: 184000/190636\n",
      "[ItemCosine-BM25@10] processed: 184500/190636\n",
      "[ItemCosine-BM25@10] processed: 185000/190636\n",
      "[ItemCosine-BM25@10] processed: 185500/190636\n",
      "[ItemCosine-BM25@10] processed: 186000/190636\n",
      "[ItemCosine-BM25@10] processed: 186500/190636\n",
      "[ItemCosine-BM25@10] processed: 187000/190636\n",
      "[ItemCosine-BM25@10] processed: 187500/190636\n",
      "[ItemCosine-BM25@10] processed: 188000/190636\n",
      "[ItemCosine-BM25@10] processed: 188500/190636\n",
      "[ItemCosine-BM25@10] processed: 189000/190636\n",
      "[ItemCosine-BM25@10] processed: 189500/190636\n",
      "[ItemCosine-BM25@10] processed: 190000/190636\n",
      "[ItemCosine-BM25@10] processed: 190500/190636\n",
      "[ItemCosine-BM25@10] processed: 190636/190636\n",
      "[SVD-BM25@10] processed: 1500/190636\n",
      "[SVD-BM25@10] processed: 3000/190636\n",
      "[SVD-BM25@10] processed: 4500/190636\n",
      "[SVD-BM25@10] processed: 6000/190636\n",
      "[SVD-BM25@10] processed: 7500/190636\n",
      "[SVD-BM25@10] processed: 9000/190636\n",
      "[SVD-BM25@10] processed: 10500/190636\n",
      "[SVD-BM25@10] processed: 12000/190636\n",
      "[SVD-BM25@10] processed: 13500/190636\n",
      "[SVD-BM25@10] processed: 15000/190636\n",
      "[SVD-BM25@10] processed: 16500/190636\n",
      "[SVD-BM25@10] processed: 18000/190636\n",
      "[SVD-BM25@10] processed: 19500/190636\n",
      "[SVD-BM25@10] processed: 21000/190636\n",
      "[SVD-BM25@10] processed: 22500/190636\n",
      "[SVD-BM25@10] processed: 24000/190636\n",
      "[SVD-BM25@10] processed: 25500/190636\n",
      "[SVD-BM25@10] processed: 27000/190636\n",
      "[SVD-BM25@10] processed: 28500/190636\n",
      "[SVD-BM25@10] processed: 30000/190636\n",
      "[SVD-BM25@10] processed: 31500/190636\n",
      "[SVD-BM25@10] processed: 33000/190636\n",
      "[SVD-BM25@10] processed: 34500/190636\n",
      "[SVD-BM25@10] processed: 36000/190636\n",
      "[SVD-BM25@10] processed: 37500/190636\n",
      "[SVD-BM25@10] processed: 39000/190636\n",
      "[SVD-BM25@10] processed: 40500/190636\n",
      "[SVD-BM25@10] processed: 42000/190636\n",
      "[SVD-BM25@10] processed: 43500/190636\n",
      "[SVD-BM25@10] processed: 45000/190636\n",
      "[SVD-BM25@10] processed: 46500/190636\n",
      "[SVD-BM25@10] processed: 48000/190636\n",
      "[SVD-BM25@10] processed: 49500/190636\n",
      "[SVD-BM25@10] processed: 51000/190636\n",
      "[SVD-BM25@10] processed: 52500/190636\n",
      "[SVD-BM25@10] processed: 54000/190636\n",
      "[SVD-BM25@10] processed: 55500/190636\n",
      "[SVD-BM25@10] processed: 57000/190636\n",
      "[SVD-BM25@10] processed: 58500/190636\n",
      "[SVD-BM25@10] processed: 60000/190636\n",
      "[SVD-BM25@10] processed: 61500/190636\n",
      "[SVD-BM25@10] processed: 63000/190636\n",
      "[SVD-BM25@10] processed: 64500/190636\n",
      "[SVD-BM25@10] processed: 66000/190636\n",
      "[SVD-BM25@10] processed: 67500/190636\n",
      "[SVD-BM25@10] processed: 69000/190636\n",
      "[SVD-BM25@10] processed: 70500/190636\n",
      "[SVD-BM25@10] processed: 72000/190636\n",
      "[SVD-BM25@10] processed: 73500/190636\n",
      "[SVD-BM25@10] processed: 75000/190636\n",
      "[SVD-BM25@10] processed: 76500/190636\n",
      "[SVD-BM25@10] processed: 78000/190636\n",
      "[SVD-BM25@10] processed: 79500/190636\n",
      "[SVD-BM25@10] processed: 81000/190636\n",
      "[SVD-BM25@10] processed: 82500/190636\n",
      "[SVD-BM25@10] processed: 84000/190636\n",
      "[SVD-BM25@10] processed: 85500/190636\n",
      "[SVD-BM25@10] processed: 87000/190636\n",
      "[SVD-BM25@10] processed: 88500/190636\n",
      "[SVD-BM25@10] processed: 90000/190636\n",
      "[SVD-BM25@10] processed: 91500/190636\n",
      "[SVD-BM25@10] processed: 93000/190636\n",
      "[SVD-BM25@10] processed: 94500/190636\n",
      "[SVD-BM25@10] processed: 96000/190636\n",
      "[SVD-BM25@10] processed: 97500/190636\n",
      "[SVD-BM25@10] processed: 99000/190636\n",
      "[SVD-BM25@10] processed: 100500/190636\n",
      "[SVD-BM25@10] processed: 102000/190636\n",
      "[SVD-BM25@10] processed: 103500/190636\n",
      "[SVD-BM25@10] processed: 105000/190636\n",
      "[SVD-BM25@10] processed: 106500/190636\n",
      "[SVD-BM25@10] processed: 108000/190636\n",
      "[SVD-BM25@10] processed: 109500/190636\n",
      "[SVD-BM25@10] processed: 111000/190636\n",
      "[SVD-BM25@10] processed: 112500/190636\n",
      "[SVD-BM25@10] processed: 114000/190636\n",
      "[SVD-BM25@10] processed: 115500/190636\n",
      "[SVD-BM25@10] processed: 117000/190636\n",
      "[SVD-BM25@10] processed: 118500/190636\n",
      "[SVD-BM25@10] processed: 120000/190636\n",
      "[SVD-BM25@10] processed: 121500/190636\n",
      "[SVD-BM25@10] processed: 123000/190636\n",
      "[SVD-BM25@10] processed: 124500/190636\n",
      "[SVD-BM25@10] processed: 126000/190636\n",
      "[SVD-BM25@10] processed: 127500/190636\n",
      "[SVD-BM25@10] processed: 129000/190636\n",
      "[SVD-BM25@10] processed: 130500/190636\n",
      "[SVD-BM25@10] processed: 132000/190636\n",
      "[SVD-BM25@10] processed: 133500/190636\n",
      "[SVD-BM25@10] processed: 135000/190636\n",
      "[SVD-BM25@10] processed: 136500/190636\n",
      "[SVD-BM25@10] processed: 138000/190636\n",
      "[SVD-BM25@10] processed: 139500/190636\n",
      "[SVD-BM25@10] processed: 141000/190636\n",
      "[SVD-BM25@10] processed: 142500/190636\n",
      "[SVD-BM25@10] processed: 144000/190636\n",
      "[SVD-BM25@10] processed: 145500/190636\n",
      "[SVD-BM25@10] processed: 147000/190636\n",
      "[SVD-BM25@10] processed: 148500/190636\n",
      "[SVD-BM25@10] processed: 150000/190636\n",
      "[SVD-BM25@10] processed: 151500/190636\n",
      "[SVD-BM25@10] processed: 153000/190636\n",
      "[SVD-BM25@10] processed: 154500/190636\n",
      "[SVD-BM25@10] processed: 156000/190636\n",
      "[SVD-BM25@10] processed: 157500/190636\n",
      "[SVD-BM25@10] processed: 159000/190636\n",
      "[SVD-BM25@10] processed: 160500/190636\n",
      "[SVD-BM25@10] processed: 162000/190636\n",
      "[SVD-BM25@10] processed: 163500/190636\n",
      "[SVD-BM25@10] processed: 165000/190636\n",
      "[SVD-BM25@10] processed: 166500/190636\n",
      "[SVD-BM25@10] processed: 168000/190636\n",
      "[SVD-BM25@10] processed: 169500/190636\n",
      "[SVD-BM25@10] processed: 171000/190636\n",
      "[SVD-BM25@10] processed: 172500/190636\n",
      "[SVD-BM25@10] processed: 174000/190636\n",
      "[SVD-BM25@10] processed: 175500/190636\n",
      "[SVD-BM25@10] processed: 177000/190636\n",
      "[SVD-BM25@10] processed: 178500/190636\n",
      "[SVD-BM25@10] processed: 180000/190636\n",
      "[SVD-BM25@10] processed: 181500/190636\n",
      "[SVD-BM25@10] processed: 183000/190636\n",
      "[SVD-BM25@10] processed: 184500/190636\n",
      "[SVD-BM25@10] processed: 186000/190636\n",
      "[SVD-BM25@10] processed: 187500/190636\n",
      "[SVD-BM25@10] processed: 189000/190636\n",
      "[SVD-BM25@10] processed: 190500/190636\n",
      "[SVD-BM25@10] processed: 190636/190636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>users</th>\n",
       "      <th>recall</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Popularity@10</td>\n",
       "      <td>190636</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ItemCosine-RAW@10</td>\n",
       "      <td>190636</td>\n",
       "      <td>0.035229</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>0.020419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ItemCosine-TFIDF@10</td>\n",
       "      <td>190636</td>\n",
       "      <td>0.035476</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.020558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ItemCosine-BM25@10</td>\n",
       "      <td>190636</td>\n",
       "      <td>0.077498</td>\n",
       "      <td>0.030939</td>\n",
       "      <td>0.041785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVD-BM25@10</td>\n",
       "      <td>190636</td>\n",
       "      <td>0.008262</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.004429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label   users    recall       map      ndcg\n",
       "0        Popularity@10  190636  0.001673  0.000469  0.000742\n",
       "1    ItemCosine-RAW@10  190636  0.035229  0.015882  0.020419\n",
       "2  ItemCosine-TFIDF@10  190636  0.035476  0.015988  0.020558\n",
       "3   ItemCosine-BM25@10  190636  0.077498  0.030939  0.041785\n",
       "4          SVD-BM25@10  190636  0.008262  0.003269  0.004429"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------- helpers: masking & topk extraction (batched) --------\n",
    "def _mask_seen_rows(scores, batch_user_idx, seen_train, neg_val=-np.inf):\n",
    "    \"\"\"Set scores of seen items to -inf for each user row.\"\"\"\n",
    "    for r, u_idx in enumerate(batch_user_idx):\n",
    "        s = seen_train.get(u_idx, None)\n",
    "        if s:\n",
    "            scores[r, list(s)] = neg_val\n",
    "\n",
    "def _rowwise_topk_indices(scores, k):\n",
    "    \"\"\"\n",
    "    For a 2D array (n_rows x n_items), return per-row top-k item indices (by column index).\n",
    "    Uses argpartition -> arg sort on the k-slice for speed.\n",
    "    \"\"\"\n",
    "    # argpartition gives unordered top-k positions\n",
    "    part = np.argpartition(-scores, kth=k-1, axis=1)[:, :k]\n",
    "    # order those k positions properly per row\n",
    "    row_idx = np.arange(scores.shape[0])[:, None]\n",
    "    part_scores = scores[row_idx, part]\n",
    "    order = np.argsort(-part_scores, axis=1)\n",
    "    return part[row_idx, order]\n",
    "\n",
    "# -------- batched recommenders (no per-user Python loops) --------\n",
    "def batch_toplist_pop(batch_user_idx, pop_order, k):\n",
    "    \"\"\"\n",
    "    Popularity baseline; same list for everyone, but we filter seen items user-wise.\n",
    "    We’ll opportunistically scan a bit more than k to avoid many re-scans.\n",
    "    \"\"\"\n",
    "    k_probe = min(len(pop_order), k + 200)  # small headroom to compensate for seen filtering\n",
    "    head = pop_order[:k_probe]\n",
    "    out = []\n",
    "    for u_idx in batch_user_idx:\n",
    "        seen = seen_train.get(u_idx, set())\n",
    "        rec = [idx2item[j] for j in head if j not in seen]\n",
    "        if len(rec) < k:\n",
    "            # fallback: extend scan if needed\n",
    "            for j in pop_order[k_probe:]:\n",
    "                if j not in seen:\n",
    "                    rec.append(idx2item[j])\n",
    "                    if len(rec) == k:\n",
    "                        break\n",
    "        out.append(rec[:k])\n",
    "    return out\n",
    "\n",
    "def batch_toplist_itemcosine(batch_user_idx, X_base, C, k):\n",
    "    \"\"\"\n",
    "    Item–item cosine in batch:\n",
    "      scores = (W @ C^T) @ C, where W = X_base[batch, :]\n",
    "    \"\"\"\n",
    "    W = X_base[batch_user_idx, :]               # (B x n_items) sparse\n",
    "    Y = (W @ C.T)                               # (B x n_users) sparse\n",
    "    S = (Y @ C).toarray()                       # (B x n_items) dense\n",
    "    _mask_seen_rows(S, batch_user_idx, seen_train, neg_val=-np.inf)\n",
    "    topk_cols = _rowwise_topk_indices(S, k)     # (B x k) item indices (train space)\n",
    "    return [[idx2item[j] for j in row] for row in topk_cols]\n",
    "\n",
    "def batch_toplist_svd(batch_user_idx, P, Q, k):\n",
    "    \"\"\"\n",
    "    SVD scoring: scores = P_batch @ Q^T (dense x dense)\n",
    "    \"\"\"\n",
    "    P_batch = P[batch_user_idx, :]              # (B x f)\n",
    "    S = P_batch @ Q.T                           # (B x n_items)\n",
    "    _mask_seen_rows(S, batch_user_idx, seen_train, neg_val=-np.inf)\n",
    "    topk_cols = _rowwise_topk_indices(S, k)\n",
    "    return [[idx2item[j] for j in row] for row in topk_cols]\n",
    "\n",
    "# -------- metrics (same as before) --------\n",
    "def recall_at_k(true_items, rec_list, k=10):\n",
    "    if not true_items: return 0.0\n",
    "    return len(set(rec_list[:k]) & set(true_items)) / len(true_items)\n",
    "\n",
    "def ap_at_k(true_items, rec_list, k=10):\n",
    "    if not true_items: return 0.0\n",
    "    true = set(true_items)\n",
    "    hits, ap = 0, 0.0\n",
    "    for i, it in enumerate(rec_list[:k], start=1):\n",
    "        if it in true:\n",
    "            hits += 1\n",
    "            ap += hits / i\n",
    "    return ap / min(len(true_items), k)\n",
    "\n",
    "def ndcg_at_k(true_items, rec_list, k=10):\n",
    "    if not true_items: return 0.0\n",
    "    true = set(true_items)\n",
    "    dcg = 0.0\n",
    "    for i, it in enumerate(rec_list[:k], start=1):\n",
    "        if it in true:\n",
    "            dcg += 1.0 / np.log2(i+1)\n",
    "    ideal = min(len(true_items), k)\n",
    "    idcg = sum(1.0 / np.log2(i+1) for i in range(1, ideal+1))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# -------- batched evaluator (all users, but processed in chunks) --------\n",
    "def eval_batched(model_name, batch_func, k=K, batch_size=20000, verbose=True):\n",
    "    users_eval = np.array([u for u in eval_users if u in user2idx])\n",
    "    n = len(users_eval)\n",
    "    recalls, maps, ndcgs = [], [], []\n",
    "    done = 0\n",
    "\n",
    "    for start in range(0, n, batch_size):\n",
    "        batch_users_orig = users_eval[start:start+batch_size]\n",
    "        batch_idx = np.array([user2idx[u] for u in batch_users_orig], dtype=int)\n",
    "\n",
    "        # truth per user (in original item ids)\n",
    "        truth_list = []\n",
    "        keep_mask = []\n",
    "        for u_orig in batch_users_orig:\n",
    "            t = [it for it in test_truth[u_orig] if it in item2idx]  # keep items known to train\n",
    "            truth_list.append(t)\n",
    "            keep_mask.append(len(t) > 0)\n",
    "\n",
    "        # filter out users with empty truth in this batch (saves scoring time)\n",
    "        keep_mask = np.array(keep_mask, dtype=bool)\n",
    "        if not keep_mask.any():\n",
    "            done += len(batch_users_orig)\n",
    "            if verbose: print(f\"[{model_name}] {done}/{n} users (no truth in batch)\")\n",
    "            continue\n",
    "        batch_users_orig = batch_users_orig[keep_mask]\n",
    "        batch_idx = batch_idx[keep_mask]\n",
    "        truth_list = [truth_list[i] for i in np.where(keep_mask)[0]]\n",
    "\n",
    "        # get recommendations for this batch (list of lists of itemids)\n",
    "        recs_batch = batch_func(batch_idx, k)\n",
    "\n",
    "        # compute metrics\n",
    "        for truth, rec in zip(truth_list, recs_batch):\n",
    "            recalls.append(recall_at_k(truth, rec, k))\n",
    "            maps.append(ap_at_k(truth, rec, k))\n",
    "            ndcgs.append(ndcg_at_k(truth, rec, k))\n",
    "\n",
    "        done += len(keep_mask)\n",
    "        if verbose:\n",
    "            print(f\"[{model_name}] processed: {min(done,n)}/{n}\")\n",
    "\n",
    "    return {\n",
    "        \"label\": model_name,\n",
    "        \"users\": len(recalls),\n",
    "        \"recall\": np.mean(recalls) if recalls else 0.0,\n",
    "        \"map\":    np.mean(maps)    if maps    else 0.0,\n",
    "        \"ndcg\":   np.mean(ndcgs)   if ndcgs   else 0.0,\n",
    "    }\n",
    "\n",
    "# -------- run models (batched) --------\n",
    "rows = []\n",
    "\n",
    "# Popularity (precomputed order from earlier cell)\n",
    "rows.append(eval_batched(\n",
    "    \"Popularity@10\",\n",
    "    batch_func=lambda batch_idx, k=K: batch_toplist_pop(batch_idx, pop_order, k),\n",
    "    k=K, batch_size=2000, verbose=True\n",
    "))\n",
    "\n",
    "# Item–Item cosine (RAW / TF-IDF / BM25)\n",
    "rows.append(eval_batched(\n",
    "    \"ItemCosine-RAW@10\",\n",
    "    batch_func=lambda batch_idx, k=K: batch_toplist_itemcosine(batch_idx, X_RAW,   C_RAW,   k),\n",
    "    k=K, batch_size=500, verbose=True   # item-cosine is heavier; smaller batch helps memory\n",
    "))\n",
    "rows.append(eval_batched(\n",
    "    \"ItemCosine-TFIDF@10\",\n",
    "    batch_func=lambda batch_idx, k=K: batch_toplist_itemcosine(batch_idx, X_TFIDF, C_TFIDF, k),\n",
    "    k=K, batch_size=500, verbose=True\n",
    "))\n",
    "rows.append(eval_batched(\n",
    "    \"ItemCosine-BM25@10\",\n",
    "    batch_func=lambda batch_idx, k=K: batch_toplist_itemcosine(batch_idx, X_BM25,  C_BM25,  k),\n",
    "    k=K, batch_size=500, verbose=True\n",
    "))\n",
    "\n",
    "# SVD on BM25\n",
    "rows.append(eval_batched(\n",
    "    \"SVD-BM25@10\",\n",
    "    batch_func=lambda batch_idx, k=K: batch_toplist_svd(batch_idx, P_bm25, Q_bm25, k),\n",
    "    k=K, batch_size=1500, verbose=True\n",
    "))\n",
    "\n",
    "eval_df = pd.DataFrame(rows)\n",
    "eval_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c7927b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "x = np.arange(len(eval_df))\n",
    "w = 0.25\n",
    "ax.bar(x - w, eval_df['recall'],   width=w, label='Recall@10')\n",
    "ax.bar(x,       eval_df['map'],     width=w, label='MAP@10')\n",
    "ax.bar(x + w,   eval_df['ndcg'],    width=w, label='NDCG@10')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(eval_df['label'], rotation=20, ha='right')\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "for spine in ('top','right'): ax.spines[spine].set_visible(False)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdd3e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ========= KNOBS (tune for speed vs quality) ========= #\n",
    "K = 10                       # top-K for evaluation\n",
    "EVENT_WEIGHTS = {'view': 1.0, 'addtocart': 5.0, 'transaction': 20.0}\n",
    "HALF_LIFE_DAYS = 21         # recency half-life for decay\n",
    "BM25_K1 = 1.2               # BM25 parameters\n",
    "BM25_B  = 0.75\n",
    "\n",
    "CAND_BM25 = 200             # #candidates from BM25 per user\n",
    "CAND_COVIS = 100            # #candidates from co-vis per user\n",
    "CAND_POP = 100              # #candidates from popularity per user\n",
    "MAX_CANDS_PER_USER = 400\n",
    "\n",
    "# co-vis session/window parameters\n",
    "SESSION_GAP_MIN = 30\n",
    "COVIS_WINDOW = 5            # consider +/- this many neighbors in a session\n",
    "TOP_COVIS_PER_ITEM = 50     # store top-N neighbors per item in co-vis table\n",
    "\n",
    "# evaluation chunking\n",
    "EVAL_CHUNK_USERS = 20_000\n",
    "\n",
    "# ===================================================== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a939a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure types\n",
    "df = pd.read_csv(\"../Data/Cleaned Dataset/final_merged_events.csv\")\n",
    "df = df.copy()\n",
    "df['event_time'] = pd.to_datetime(df['event_time'])\n",
    "df = df.sort_values('event_time')\n",
    "\n",
    "# Keep only events we care about\n",
    "df = df[df['event'].isin(['view', 'addtocart', 'transaction'])]\n",
    "\n",
    "# Add date for temporal splits & recency\n",
    "df['date'] = df['event_time'].dt.date\n",
    "df['ts'] = df['event_time'].astype('int64') // 10**9  # seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6c0ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2015-05-03 03:00:04.384000 → 2015-08-05 18:04:34.556000 1984060\n",
      "Val  : 2015-08-05 18:04:38.117000 → 2015-08-18 04:23:01.129000 220452\n",
      "Test : 2015-08-18 04:23:20.445000 → 2015-09-18 02:59:47.788000 551129\n"
     ]
    }
   ],
   "source": [
    "times = df['event_time'].sort_values()\n",
    "t80 = times.quantile(0.8)\n",
    "t90_train = times[times <= t80].quantile(0.9)\n",
    "\n",
    "df_train_full = df[df['event_time'] <= t80]\n",
    "df_val = df_train_full[df_train_full['event_time'] > t90_train]\n",
    "df_train = df_train_full[df_train_full['event_time'] <= t90_train]\n",
    "df_test  = df[df['event_time'] > t80]\n",
    "\n",
    "print(\"Train:\", df_train['event_time'].min(), \"→\", df_train['event_time'].max(), len(df_train))\n",
    "print(\"Val  :\", df_val['event_time'].min(),   \"→\", df_val['event_time'].max(),   len(df_val))\n",
    "print(\"Test :\", df_test['event_time'].min(),  \"→\", df_test['event_time'].max(),  len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4749ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recency decay weights\n",
    "def recency_decay(ts_series, ref_ts, half_life_days=HALF_LIFE_DAYS):\n",
    "    hl_seconds = half_life_days * 24 * 3600\n",
    "    dt = (ref_ts - ts_series).clip(lower=0)\n",
    "    return np.exp(-np.log(2) * dt / hl_seconds)\n",
    "\n",
    "# reference time = end of train\n",
    "ref_ts = int(df_train['ts'].max())\n",
    "\n",
    "def make_weighted_interactions(df_part):\n",
    "    base = df_part['event'].map(EVENT_WEIGHTS).astype(float)\n",
    "    decay = recency_decay(df_part['ts'], ref_ts)\n",
    "    return base * decay\n",
    "\n",
    "df_train = df_train.copy()\n",
    "df_train['w'] = make_weighted_interactions(df_train)\n",
    "\n",
    "# Build user & item index maps from TRAIN ONLY\n",
    "unique_users = df_train['visitorid'].unique()\n",
    "unique_items = df_train['itemid'].unique()\n",
    "user2idx = {u:i for i,u in enumerate(unique_users)}\n",
    "item2idx = {it:j for j,it in enumerate(unique_items)}\n",
    "\n",
    "# Sparse matrix (users x items) from train\n",
    "rows = df_train['visitorid'].map(user2idx).values\n",
    "cols = df_train['itemid'].map(item2idx).values\n",
    "data = df_train['w'].values\n",
    "X_train_raw = coo_matrix((data, (rows, cols)),\n",
    "                         shape=(len(unique_users), len(unique_items))).tocsr()\n",
    "\n",
    "# BM25 weighting on users x items\n",
    "def bm25_weight(X, K1=BM25_K1, B=BM25_B):\n",
    "    # X is csr (users x items)\n",
    "    # BM25 per item (column) using per-user lengths\n",
    "    X = X.tocoo()\n",
    "    n_users, n_items = X.shape\n",
    "    # doc length = per-user nnz sum\n",
    "    user_len = np.asarray(X.sum(axis=1)).ravel()\n",
    "    avg_len = user_len.mean() if n_users > 0 else 1.0\n",
    "\n",
    "    # idf per item\n",
    "    # df_j = number of users who interacted with item j\n",
    "    df_items = np.diff(X.tocsc().indptr)  # length = n_items\n",
    "    idf = np.log((n_users - df_items + 0.5) / (df_items + 0.5)).clip(min=0)\n",
    "\n",
    "    # BM25 transform each non-zero x_ij\n",
    "    # w_ij = idf_j * (x_ij*(K1+1)) / (x_ij + K1*(1 - B + B*len_i/avg_len))\n",
    "    x = X.data\n",
    "    i = X.row\n",
    "    j = X.col\n",
    "    denom = x + K1 * (1.0 - B + B * (user_len[i] / (avg_len + 1e-9)))\n",
    "    w = idf[j] * (x * (K1 + 1.0)) / (denom + 1e-9)\n",
    "    X_bm25 = coo_matrix((w, (i, j)), shape=X.shape).tocsr()\n",
    "    return X_bm25\n",
    "\n",
    "X_train_bm25 = bm25_weight(X_train_raw)\n",
    "\n",
    "# L2-normalize item columns for cosine scoring\n",
    "def l2_normalize_columns(X):\n",
    "    Xc = X.tocsc(copy=True)\n",
    "    norms = np.sqrt(np.asarray(Xc.power(2).sum(axis=0)).ravel()) + 1e-12\n",
    "    Xc.data /= norms[Xc.indices]  # careful: indices on CSC are row indices\n",
    "    return Xc.tocsr()\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "X_cols_norm = normalize(X_train_bm25, norm='l2', axis=0, copy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c052afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popularity (weighted) from train\n",
    "pop_item_counts = (\n",
    "    df_train.groupby('itemid')['w'].sum().sort_values(ascending=False)\n",
    ")\n",
    "popular_items_idx = [item2idx[it] for it in pop_item_counts.index if it in item2idx]\n",
    "\n",
    "# ---- Co-visitation (session-level) ----\n",
    "def build_covis(df_part, session_gap_min=SESSION_GAP_MIN, window=COVIS_WINDOW, topN=TOP_COVIS_PER_ITEM):\n",
    "    # work on views+addtocart+transaction (optionally views only)\n",
    "    d = df_part[['visitorid','itemid','event_time']].copy()\n",
    "    d = d.sort_values(['visitorid','event_time'])\n",
    "    # sessionize per user\n",
    "    d['prev_time'] = d.groupby('visitorid')['event_time'].shift(1)\n",
    "    gap = (d['event_time'] - d['prev_time']).dt.total_seconds().fillna(0)\n",
    "    d['session_id'] = (gap > session_gap_min*60).groupby(d['visitorid']).cumsum()\n",
    "\n",
    "    covis = defaultdict(Counter)\n",
    "    for (uid, sid), g in d.groupby(['visitorid','session_id'], sort=False):\n",
    "        items = g['itemid'].tolist()\n",
    "        n = len(items)\n",
    "        # sliding window pairs\n",
    "        for p in range(n):\n",
    "            a = items[p]\n",
    "            start = max(0, p - window)\n",
    "            end   = min(n, p + window + 1)\n",
    "            for q in range(start, end):\n",
    "                if q == p: \n",
    "                    continue\n",
    "                b = items[q]\n",
    "                covis[a][b] += 1\n",
    "    # keep top neighbors\n",
    "    covis_top = {}\n",
    "    for a, ctr in covis.items():\n",
    "        covis_top[a] = [b for b,_ in ctr.most_common(topN)]\n",
    "    return covis_top\n",
    "\n",
    "covis_neighbors = build_covis(df_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e1665ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: get seen items per user (from train)\n",
    "seen_by_user = defaultdict(set)\n",
    "for u, it in zip(df_train['visitorid'].map(user2idx, na_action='ignore'),\n",
    "                 df_train['itemid'].map(item2idx, na_action='ignore')):\n",
    "    if pd.isna(u) or pd.isna(it): \n",
    "        continue\n",
    "    seen_by_user[int(u)].add(int(it))\n",
    "\n",
    "def bm25_candidates_for_user(u_idx, topn=CAND_BM25):\n",
    "    # user profile row (1 x n_items)\n",
    "    u_row = X_train_bm25[u_idx, :]\n",
    "    scores = u_row.dot(X_cols_norm).toarray().ravel()\n",
    "    # remove seen\n",
    "    if seen_by_user.get(u_idx):\n",
    "        scores[list(seen_by_user[u_idx])] = -1e12\n",
    "    idx = np.argpartition(-scores, kth=min(topn, len(scores)-1))[:topn]\n",
    "    idx = idx[np.argsort(-scores[idx])]\n",
    "    return idx, scores[idx]\n",
    "\n",
    "def covis_candidates_for_user(u_idx, topn=CAND_COVIS):\n",
    "    # take most recent items for that user in train\n",
    "    uid = unique_users[u_idx]\n",
    "    last_items = (\n",
    "        df_train[df_train['visitorid']==uid]\n",
    "        .sort_values('event_time')\n",
    "        .tail(20)['itemid'].tolist()\n",
    "    )\n",
    "    cand = []\n",
    "    for it in reversed(last_items):\n",
    "        neighbors = covis_neighbors.get(it, [])\n",
    "        cand.extend(neighbors)\n",
    "        if len(cand) >= topn*2:  # oversample; will de-dup later\n",
    "            break\n",
    "    cand = [item2idx[it] for it in cand if it in item2idx]\n",
    "    # remove seen + keep topn by frequency approximation\n",
    "    cand = [c for c in cand if c not in seen_by_user.get(u_idx, set())]\n",
    "    # simple frequency sort\n",
    "    fre = Counter(cand)\n",
    "    top = [c for c,_ in fre.most_common(topn)]\n",
    "    # fake scores = frequency\n",
    "    sc = np.array([fre[c] for c in top], dtype=float)\n",
    "    return np.array(top, dtype=int), sc\n",
    "\n",
    "def pop_candidates_for_user(u_idx, topn=CAND_POP):\n",
    "    # remove seen\n",
    "    seen = seen_by_user.get(u_idx, set())\n",
    "    out = [j for j in popular_items_idx if j not in seen][:topn]\n",
    "    sc  = np.arange(len(out), 0, -1, dtype=float)  # simple descending score\n",
    "    return np.array(out, dtype=int), sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c70b9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== FAST PRECOMPUTE OF SIGNALS (vectorized, memory-aware) ====\n",
    "# expects: df_train with columns ['visitorid','itemid','event','event_time','w','categoryid']\n",
    "#          unique_items (array-like of item ids), unique_users (array-like of user ids)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure types are friendly\n",
    "df_train = df_train.copy()\n",
    "df_train['event'] = df_train['event'].astype('category')\n",
    "# keep categoryid as float if you have NaNs; we'll encode to integer codes below\n",
    "\n",
    "# Ensure indexers\n",
    "unique_items = pd.Index(unique_items)\n",
    "unique_users = pd.Index(unique_users)\n",
    "\n",
    "# 1) Item popularity (sum of weights) — aligned to all unique_items\n",
    "item_pop_train = (\n",
    "    df_train.groupby('itemid', observed=True)['w']\n",
    "    .sum()\n",
    "    .reindex(unique_items, fill_value=0.0)\n",
    "    .astype('float32')\n",
    ")\n",
    "\n",
    "# 2) Item freshness (recency in days) — aligned to all unique_items\n",
    "last_seen = (\n",
    "    df_train.groupby('itemid', observed=True)['event_time']\n",
    "    .max()\n",
    "    .reindex(unique_items)\n",
    ")\n",
    "age_days = (df_train['event_time'].max() - last_seen).dt.days.fillna(999).astype('float32')\n",
    "item_freshness = (1.0 / (1.0 + age_days)).astype('float32')  # 0..1, newer → larger\n",
    "\n",
    "# 3) Category conversion rate (smoothed)\n",
    "train_views = (\n",
    "    df_train.loc[df_train['event'].eq('view')]\n",
    "    .groupby('categoryid', observed=True)['itemid']\n",
    "    .count()\n",
    ")\n",
    "train_txn = (\n",
    "    df_train.loc[df_train['event'].eq('transaction')]\n",
    "    .groupby('categoryid', observed=True)['itemid']\n",
    "    .count()\n",
    ")\n",
    "conv_cat = ((train_txn.add(20, fill_value=0) / train_views.add(100, fill_value=0))).astype('float32')  # Laplace smoothing\n",
    "\n",
    "# 4) Item → category (take the last category seen per item, vectorized)\n",
    "#    Sort once, take groupby-last (fast & avoids Python loops)\n",
    "item_cat = (\n",
    "    df_train[['itemid','categoryid','event_time']]\n",
    "    .sort_values(['itemid','event_time'])\n",
    "    .groupby('itemid', observed=True)['categoryid']\n",
    "    .last()\n",
    "    .reindex(unique_items)\n",
    ")\n",
    "\n",
    "# 5) User–category affinity = share of user’s weighted interactions in each category (vectorized)\n",
    "sum_uc = df_train.groupby(['visitorid','categoryid'], observed=True)['w'].sum()\n",
    "user_cat = (sum_uc / sum_uc.groupby(level=0).transform('sum')).astype('float32')\n",
    "# If you need a plain dict for quick lookups:\n",
    "user_cat_dict = user_cat.to_dict()  # keys: (visitorid, categoryid) → float in [0,1]\n",
    "\n",
    "# ---- Build arrays for constant-time lookups by item index ----\n",
    "\n",
    "# Encode item categories as integer codes for array indexing\n",
    "item_cat_c = pd.Categorical(item_cat)  # categories are sorted unique non-NaN category IDs\n",
    "cat_codes = item_cat_c.codes.astype('int32')        # -1 for NaN\n",
    "cat_values = pd.Index(item_cat_c.categories)        # actual categoryid values\n",
    "\n",
    "# Map conv rate to category-code space\n",
    "conv_per_code = np.zeros(len(cat_values), dtype='float32')\n",
    "if len(cat_values) > 0:\n",
    "    conv_per_code = conv_cat.reindex(cat_values, fill_value=0.0).to_numpy(dtype='float32')\n",
    "\n",
    "# Final per-item arrays (index by item_idx)\n",
    "item_pop_arr    = item_pop_train.to_numpy(dtype='float32')\n",
    "item_fresh_arr  = item_freshness.to_numpy(dtype='float32')\n",
    "item_cat_code   = cat_codes                                   # -1 means \"unknown\"\n",
    "item_conv_arr   = np.where(item_cat_code >= 0, conv_per_code[item_cat_code], 0.0).astype('float32')\n",
    "\n",
    "# Optional: quick helpers that DO NOT touch df_train again\n",
    "def get_item_meta_fast(item_idx: int):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      cat_code (int), pop (float), fresh (float), conv_rate (float)\n",
    "    \"\"\"\n",
    "    c = item_cat_code[item_idx]\n",
    "    pop = float(item_pop_arr[item_idx])\n",
    "    fresh = float(item_fresh_arr[item_idx])\n",
    "    conv = float(item_conv_arr[item_idx])\n",
    "    return c, pop, fresh, conv\n",
    "\n",
    "def get_user_cat_affinity_fast(user_idx: int, cat_code: int):\n",
    "    \"\"\"\n",
    "    cat_code is from item_cat_code. Returns 0.0 if unknown/no affinity.\n",
    "    \"\"\"\n",
    "    if cat_code < 0:\n",
    "        return 0.0\n",
    "    # map back from user_idx → original visitorid, and cat_code → categoryid value\n",
    "    uid = unique_users[user_idx]\n",
    "    catid = cat_values[cat_code]\n",
    "    return float(user_cat_dict.get((uid, catid), 0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab0c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes — X_train: (1007109, 203358)  X_BM25: (1007109, 203358)  C_BM25: (1007109, 203358)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "# 0) Defaults (if not already set)\n",
    "\n",
    "K = globals().get('K', 10)\n",
    "CHUNK_USERS = globals().get('CHUNK_USERS', 20000)\n",
    "CAND_K = globals().get('CAND_K', 200)\n",
    "\n",
    "# Sanity: we expect df_train/df_test with columns at least ['visitorid','itemid','event','event_time']\n",
    "assert {'visitorid','itemid','event'}.issubset(df_train.columns)\n",
    "assert {'visitorid','itemid','event'}.issubset(df_test.columns)\n",
    "\n",
    "# If event weights not present, make them\n",
    "if 'w' not in df_train.columns:\n",
    "    w_map = {'view': 1.0, 'addtocart': 3.0, 'transaction': 5.0}\n",
    "    df_train = df_train.assign(w=df_train['event'].map(w_map).fillna(0.5))\n",
    "\n",
    "\n",
    "# 1) Train-only mappings (critical)\n",
    "\n",
    "users_train = np.unique(df_train['visitorid'].values)\n",
    "items_train = np.unique(df_train['itemid'].values)\n",
    "\n",
    "user2idx = {u: i for i, u in enumerate(users_train)}\n",
    "item2idx = {it: j for j, it in enumerate(items_train)}\n",
    "\n",
    "unique_users = users_train\n",
    "unique_items = items_train\n",
    "\n",
    "\n",
    "# 2) Build CSR interaction matrix (train)\n",
    "\n",
    "row = df_train['visitorid'].map(user2idx).values\n",
    "col = df_train['itemid'].map(item2idx).values\n",
    "dat = df_train['w'].astype(float).values\n",
    "\n",
    "n_users = len(unique_users)\n",
    "n_items = len(unique_items)\n",
    "\n",
    "X_train = coo_matrix((dat, (row, col)), shape=(n_users, n_items)).tocsr()\n",
    "X_train.sum_duplicates()\n",
    "\n",
    "# Seen items per user (for filtering)\n",
    "from collections import defaultdict\n",
    "seen_train = defaultdict(set)\n",
    "for r, c in zip(row, col):\n",
    "    seen_train[r].add(c)\n",
    "\n",
    "\n",
    "# 3) Weighting & safe column L2-normalization\n",
    "\n",
    "def tfidf_weight(X):\n",
    "    # X: csr\n",
    "    Xc = X.tocsc(copy=True)\n",
    "    n_rows, n_cols = Xc.shape\n",
    "    # document frequency (per column nnz)\n",
    "    df_col = np.diff(Xc.indptr)\n",
    "    idf = np.log((n_rows + 1) / (df_col + 1)) + 1.0  # smoothed idf\n",
    "    # tf = log(1 + x)\n",
    "    Xc.data = np.log1p(Xc.data)\n",
    "    Xc.data *= np.repeat(idf, df_col)\n",
    "    return Xc.tocsr()\n",
    "\n",
    "def bm25_weight(X, K1=1.2, B=0.75):\n",
    "    # Work in CSR for per-row length normalization\n",
    "    X = X.tocsr(copy=True)\n",
    "    n_rows, n_cols = X.shape\n",
    "\n",
    "    # idf from column nnz\n",
    "    Xc = X.tocsc()\n",
    "    df_col = np.diff(Xc.indptr)\n",
    "    idf = np.log((n_rows - df_col + 0.5) / (df_col + 0.5))\n",
    "    idf[idf < 0] = 0.0\n",
    "\n",
    "    # row lengths\n",
    "    row_sums = np.asarray(X.sum(axis=1)).ravel()\n",
    "    avgdl = row_sums.mean() + 1e-12\n",
    "    denom_row = K1 * (1 - B + B * (row_sums / avgdl))\n",
    "\n",
    "    # expand row indices per data entry\n",
    "    row_ids = np.repeat(np.arange(n_rows), np.diff(X.indptr))\n",
    "    col_ids = X.indices\n",
    "\n",
    "    tf_prime = (X.data * (K1 + 1.0)) / (X.data + denom_row[row_ids] + 1e-12)\n",
    "    X.data = tf_prime * idf[col_ids]\n",
    "    return X\n",
    "\n",
    "def l2_normalize_columns(X):\n",
    "    # Normalize columns so that cosine(item_i, item_j) works\n",
    "    Xc = X.tocsc(copy=True)\n",
    "    col_norms = np.sqrt(Xc.power(2).sum(axis=0)).A1\n",
    "    col_norms[col_norms == 0] = 1.0\n",
    "    # repeat each column norm for the number of nonzeros in that column\n",
    "    scale = np.repeat(col_norms, np.diff(Xc.indptr))\n",
    "    Xc.data = Xc.data / scale\n",
    "    return Xc.tocsr()\n",
    "\n",
    "# Choose base matrix variant (BM25 typically best here)\n",
    "X_BM25 = bm25_weight(X_train)\n",
    "C_BM25 = l2_normalize_columns(X_BM25)  # same shape (users x items), cols L2-normalized\n",
    "\n",
    "\n",
    "# 4) Base recommender & toplists (item-cosine via two sparse multiplies)\n",
    "\n",
    "def recommend_itemcosine(u_idx, X, C, k=K):\n",
    "    \"\"\"\n",
    "    X: users x items CSR (weighted interactions)\n",
    "    C: users x items CSR with L2-normalized columns\n",
    "    Predict scores = (X[u,:] @ C.T) @ C  (implicit item-item cosine)\n",
    "    \"\"\"\n",
    "    if u_idx >= X.shape[0]:\n",
    "        return [], []\n",
    "    w = X[u_idx, :]        # 1 x n_items\n",
    "    if w.nnz == 0:\n",
    "        return [], []\n",
    "\n",
    "    y = (w @ C.T)          # 1 x n_users\n",
    "    scores = (y @ C).toarray().ravel()  # 1 x n_items -> dense row\n",
    "\n",
    "    # filter seen\n",
    "    for it in seen_train.get(u_idx, ()):\n",
    "        scores[it] = -np.inf\n",
    "\n",
    "    if k >= len(scores):\n",
    "        top_idx = np.argsort(-scores)\n",
    "    else:\n",
    "        top_part = np.argpartition(-scores, k)[:k]\n",
    "        top_idx = top_part[np.argsort(-scores[top_part])]\n",
    "    return top_idx[:k].tolist(), scores[top_idx[:k]].tolist()\n",
    "\n",
    "def toplist_itemcosine_bm25(u_idx, k=K):\n",
    "    idx, _ = recommend_itemcosine(u_idx, X_BM25, C_BM25, k)\n",
    "    return idx\n",
    "\n",
    "# Popularity baseline toplist (train popularity)\n",
    "item_pop_train = np.asarray(X_train.sum(axis=0)).ravel()\n",
    "pop_rank = np.argsort(-item_pop_train)\n",
    "\n",
    "def toplist_pop(u_idx, k=K):\n",
    "    # filter seen for this user\n",
    "    seen = seen_train.get(u_idx, set())\n",
    "    if not seen:\n",
    "        return pop_rank[:k].tolist()\n",
    "    # walk down the popularity list skipping seen\n",
    "    out = []\n",
    "    for it in pop_rank:\n",
    "        if it not in seen:\n",
    "            out.append(it)\n",
    "            if len(out) >= k:\n",
    "                break\n",
    "    return out\n",
    "\n",
    "\n",
    "# 5) Test ground-truth (transactions) & eval users aligned to train space\n",
    "\n",
    "test_txn = (\n",
    "    df_test[df_test['event'] == 'transaction']\n",
    "    .groupby('visitorid')['itemid'].apply(set).to_dict()\n",
    ")\n",
    "# users to evaluate: must exist in train mapping\n",
    "eval_users = [u for u in df_test['visitorid'].unique() if u in user2idx]\n",
    "test_truth = test_txn  # alias if your notebook expects this name\n",
    "\n",
    "\n",
    "# 6) Metric helpers (idempotent re-def ok)\n",
    "\n",
    "def recall_at_k(truth_set, rec_list, k):\n",
    "    if not truth_set: return 0.0\n",
    "    hit = len(set(rec_list[:k]) & set(truth_set))\n",
    "    return hit / float(len(truth_set))\n",
    "\n",
    "def ap_at_k(truth_set, rec_list, k):\n",
    "    if not truth_set: return 0.0\n",
    "    score = 0.0\n",
    "    hit = 0\n",
    "    for i, itm in enumerate(rec_list[:k], 1):\n",
    "        if itm in truth_set:\n",
    "            hit += 1\n",
    "            score += hit / i\n",
    "    return score / min(len(truth_set), k) if hit else 0.0\n",
    "\n",
    "def ndcg_at_k(truth_set, rec_list, k):\n",
    "    import math\n",
    "    dcg = 0.0\n",
    "    for i, itm in enumerate(rec_list[:k], 1):\n",
    "        if itm in truth_set:\n",
    "            dcg += 1.0 / math.log2(i + 1)\n",
    "    ideal = 0.0\n",
    "    m = min(len(truth_set), k)\n",
    "    for i in range(1, m + 1):\n",
    "        ideal += 1.0 / math.log2(i + 1)\n",
    "    return dcg / ideal if ideal > 0 else 0.0\n",
    "\n",
    "\n",
    "# 7) Reranker (unchanged; uses metadata you already calculated)\n",
    "\n",
    "def rerank_with_metadata(user_idx, base_items, w_base, w_pop, w_fresh, w_conv, w_aff, rank_decay, k=K):\n",
    "    base_items = np.array(base_items, dtype=np.int64)\n",
    "    if base_items.size == 0: \n",
    "        return np.array([], dtype=np.int64)\n",
    "\n",
    "    # base rank score\n",
    "    rank_pos = np.arange(1, base_items.size + 1, dtype=np.float64)\n",
    "    s_base = 1.0 / (rank_pos ** rank_decay)\n",
    "\n",
    "    # fetch per-item metadata (must exist in your notebook: item_pop_train, item_freshness, conv_cat, user_cat, etc.)\n",
    "    pop = np.array([item_pop_train[unique_items[it]] if unique_items[it] in item_pop_train.index else 0.0\n",
    "                    for it in base_items], dtype=np.float64)\n",
    "    fresh = np.array([item_freshness.get(unique_items[it], 0.0) for it in base_items], dtype=np.float64)\n",
    "\n",
    "    # category & conv rate\n",
    "    cats = []\n",
    "    for it in base_items:\n",
    "        it_orig = unique_items[it]\n",
    "        cat_vals = df_train.loc[df_train['itemid'].eq(it_orig), 'categoryid'].tail(1).values\n",
    "        cats.append(cat_vals[0] if len(cat_vals) else np.nan)\n",
    "    cats = np.array(cats)\n",
    "    conv = np.array([float(conv_cat.get(c, 0.0)) if pd.notna(c) else 0.0 for c in cats], dtype=np.float64)\n",
    "\n",
    "    # user affinity to category\n",
    "    uid_orig = unique_users[user_idx]\n",
    "    def user_cat_aff(c):\n",
    "        if pd.isna(c): return 0.0\n",
    "        return float(user_cat.get((uid_orig, c), 0.0))\n",
    "    aff = np.array([user_cat_aff(c) for c in cats], dtype=np.float64)\n",
    "\n",
    "    # combine\n",
    "    s = (w_base * s_base) + (w_pop * pop) + (w_fresh * fresh) + (w_conv * conv) + (w_aff * aff)\n",
    "    order = np.argsort(-s)\n",
    "    return base_items[order][:k]\n",
    "\n",
    "\n",
    "# 8) Eval wrapper (baseline vs. hybrid)\n",
    "\n",
    "def eval_hybrid(weights, label, users_eval=None, chunk_size=CHUNK_USERS, k=K, cand_k=CAND_K):\n",
    "    \"\"\"\n",
    "    weights None => 'no-rerank' baseline using toplist_itemcosine_bm25(u,k)\n",
    "    \"\"\"\n",
    "    if users_eval is None:\n",
    "        users_eval = [u for u in eval_users if u in user2idx]\n",
    "\n",
    "    recalls, maps, ndcgs = [], [], []\n",
    "    n_users = len(users_eval)\n",
    "\n",
    "    for start in range(0, n_users, chunk_size):\n",
    "        batch = users_eval[start:start+chunk_size]\n",
    "        for u_orig in batch:\n",
    "            u_idx = user2idx[u_orig]\n",
    "\n",
    "            truth_items = test_truth.get(u_orig, set())\n",
    "            truth_idx = { item2idx[it] for it in truth_items if it in item2idx }\n",
    "            if not truth_idx:\n",
    "                continue\n",
    "\n",
    "            if weights is None:\n",
    "                rec_idx = toplist_itemcosine_bm25(u_idx, k)\n",
    "            else:\n",
    "                w_base, w_pop, w_fresh, w_conv, w_aff, rd = weights\n",
    "                base_idx = toplist_itemcosine_bm25(u_idx, cand_k)\n",
    "                if not base_idx:\n",
    "                    continue\n",
    "                rec_idx = rerank_with_metadata(\n",
    "                    user_idx=u_idx,\n",
    "                    base_items=base_idx,\n",
    "                    w_base=w_base, w_pop=w_pop, w_fresh=w_fresh, w_conv=w_conv, w_aff=w_aff,\n",
    "                    rank_decay=rd, k=k\n",
    "                ).tolist()\n",
    "\n",
    "            if not rec_idx:\n",
    "                continue\n",
    "\n",
    "            recalls.append(recall_at_k(truth_idx, rec_idx, k))\n",
    "            maps.append(ap_at_k(truth_idx, rec_idx, k))\n",
    "            ndcgs.append(ndcg_at_k(truth_idx, rec_idx, k))\n",
    "\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"users\": len(recalls),\n",
    "        \"recall\": float(np.mean(recalls)) if recalls else 0.0,\n",
    "        \"map\":    float(np.mean(maps))    if maps    else 0.0,\n",
    "        \"ndcg\":   float(np.mean(ndcgs))   if ndcgs   else 0.0,\n",
    "    }\n",
    "\n",
    "print(\"Shapes — X_train:\", X_train.shape, \" X_BM25:\", X_BM25.shape, \" C_BM25:\", C_BM25.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3555c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Popularity array (by item index) + normalized variant for mixing ---\n",
    "item_pop_arr = np.asarray(X_train.sum(axis=0)).ravel()\n",
    "if item_pop_arr.max() > 0:\n",
    "    pop_norm = np.log1p(item_pop_arr) / np.log1p(item_pop_arr.max())\n",
    "else:\n",
    "    pop_norm = item_pop_arr.copy()  # all zeros edge case\n",
    "\n",
    "# Keep your existing popularity ranking for the baseline toplist\n",
    "pop_rank = np.argsort(-item_pop_arr)\n",
    "\n",
    "# --- 2) Fast item -> category map (last seen in train) ---\n",
    "item_to_cat = (\n",
    "    df_train.sort_values('event_time')\n",
    "            .groupby('itemid')['categoryid']\n",
    "            .last()\n",
    "            .to_dict()\n",
    ")\n",
    "\n",
    "# --- 3) (Optional) convert user_cat to a plain dict for faster .get() ---\n",
    "# user_cat was defined earlier as a normalized share per user/category\n",
    "user_cat_dict = user_cat.to_dict() if hasattr(user_cat, \"to_dict\") else user_cat\n",
    "\n",
    "# --- 4) Replace your reranker to use arrays/dicts (no .index checks) ---\n",
    "def rerank_with_metadata(user_idx, base_items, w_base, w_pop, w_fresh, w_conv, w_aff, rank_decay, k=K):\n",
    "    \"\"\"\n",
    "    base_items: array/list of item *indices* (cols), length = CAND_K\n",
    "    Returns top-k item indices after re-ranking with a simple linear score.\n",
    "    \"\"\"\n",
    "    base_items = np.asarray(base_items, dtype=np.int64)\n",
    "    if base_items.size == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "\n",
    "    # base rank decay (higher rank -> higher score)\n",
    "    rank_pos = np.arange(1, base_items.size + 1, dtype=np.float64)\n",
    "    s_base = 1.0 / (rank_pos ** rank_decay)\n",
    "\n",
    "    # --- popularity component (array, indexed by item index) ---\n",
    "    pop = pop_norm[base_items]  # already 0..1\n",
    "\n",
    "    # --- freshness component (map by original item id -> 0..1) ---\n",
    "    it_orig = unique_items[base_items]  # original item ids for these indices\n",
    "    fresh = np.array([float(item_freshness.get(it, 0.0)) for it in it_orig], dtype=np.float64)\n",
    "\n",
    "    # --- category conversion rate (by category id) ---\n",
    "    cats = np.array([item_to_cat.get(it, np.nan) for it in it_orig], dtype='float64')\n",
    "    conv = np.array([float(conv_cat.get(c, 0.0)) if pd.notna(c) else 0.0 for c in cats], dtype=np.float64)\n",
    "\n",
    "    # --- user-category affinity ---\n",
    "    u_orig = unique_users[user_idx]\n",
    "    def u_aff(c):\n",
    "        if pd.isna(c): \n",
    "            return 0.0\n",
    "        return float(user_cat_dict.get((u_orig, c), 0.0))\n",
    "    aff = np.array([u_aff(c) for c in cats], dtype=np.float64)\n",
    "\n",
    "    # --- linear blend ---\n",
    "    s = (w_base * s_base) + (w_pop * pop) + (w_fresh * fresh) + (w_conv * conv) + (w_aff * aff)\n",
    "\n",
    "    order = np.argsort(-s)\n",
    "    return base_items[order][:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "165235cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>users</th>\n",
       "      <th>recall</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hybrid@10 wb=0.8 wp=0.3 wf=0.3 wc=0.2 wa=0.5 r...</td>\n",
       "      <td>248</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.018005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hybrid@10 wb=0.9 wp=0.2 wf=0.2 wc=0.2 wa=0.4 r...</td>\n",
       "      <td>248</td>\n",
       "      <td>0.028973</td>\n",
       "      <td>0.010122</td>\n",
       "      <td>0.015444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hybrid@10 wb=0.7 wp=0.4 wf=0.2 wc=0.2 wa=0.5 r...</td>\n",
       "      <td>248</td>\n",
       "      <td>0.028973</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>0.017472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ItemCosine-BM25@10 (no-rerank)</td>\n",
       "      <td>248</td>\n",
       "      <td>0.012769</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>0.008415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  users    recall  \\\n",
       "0  Hybrid@10 wb=0.8 wp=0.3 wf=0.3 wc=0.2 wa=0.5 r...    248  0.029779   \n",
       "1  Hybrid@10 wb=0.9 wp=0.2 wf=0.2 wc=0.2 wa=0.4 r...    248  0.028973   \n",
       "2  Hybrid@10 wb=0.7 wp=0.4 wf=0.2 wc=0.2 wa=0.5 r...    248  0.028973   \n",
       "3                     ItemCosine-BM25@10 (no-rerank)    248  0.012769   \n",
       "\n",
       "        map      ndcg  \n",
       "0  0.012739  0.018005  \n",
       "1  0.010122  0.015444  \n",
       "2  0.012477  0.017472  \n",
       "3  0.006448  0.008415  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline: no rerank\n",
    "rows = [eval_hybrid(None, label=\"ItemCosine-BM25@10 (no-rerank)\")]\n",
    "\n",
    "# A tiny weight grid (adjust as you like)\n",
    "weight_grid = [\n",
    "    (0.9, 0.2, 0.2, 0.2, 0.4, 0.7),\n",
    "    (0.8, 0.3, 0.3, 0.2, 0.5, 0.6),\n",
    "    (0.7, 0.4, 0.2, 0.2, 0.5, 0.5),\n",
    "]\n",
    "\n",
    "for w in weight_grid:\n",
    "    lbl = f\"Hybrid@10 wb={w[0]} wp={w[1]} wf={w[2]} wc={w[3]} wa={w[4]} rd={w[5]}\"\n",
    "    rows.append(eval_hybrid(w, label=lbl))\n",
    "\n",
    "eval_hybrid_df = pd.DataFrame(rows).sort_values('recall', ascending=False).reset_index(drop=True)\n",
    "eval_hybrid_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8175fd",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Key Insights \n",
    "\n",
    "- **Personalization > Popularity.** At K=10, the personalized **Item–Item BM25** model vastly outperforms the Popularity baseline  \n",
    "  *(Popularity: Recall≈0.0017 / NDCG≈0.0007 → Item–Item BM25: Recall≈0.0775 / NDCG≈0.0418).*\n",
    "\n",
    "- **Best candidate generator:** **Item–Item BM25** is the strongest of the item–item variants; **TF-IDF** and **RAW** trails it, and **SVD(BM25)** is weakest on its own (still useful as a blended signal).\n",
    "\n",
    "- **Hybrid re-ranking lifts quality.** Adding simple business signals (popularity, freshness/age, user–category affinity) on top of base scores **roughly doubles NDCG@10** on the re-rank evaluation cohort *(≈0.0084 → ≈0.0180).*\n",
    "\n",
    "- **Recency matters in practice.** The time-decay (HALF_LIFE≈21 days) and freshness weighting contribute to the observed re-rank gains, indicating recent behavior is more predictive.\n",
    "\n",
    "- **Scope:** Results are computed for **returning users with history**. True cold-start users are **not evaluated** here; a **Trending/Popular** fallback is appropriate until interactions are observed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b3c5a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User x Category matrix: (1236032, 1086) (nnz=1,441,557)\n",
      "SVD components: 32 | explained variance ≈ 33.88%\n"
     ]
    }
   ],
   "source": [
    "# ==== User segmentation for Q3: Similar interests / purchase patterns ====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Use train set if available, else the merged df\n",
    "df = pd.read_csv(\"../Data/Cleaned Dataset/final_merged_events.csv\")\n",
    "DF = globals().get('df_train', globals().get('df'))\n",
    "assert DF is not None, \"I need a DataFrame named df or df_train with columns: visitorid, event, categoryid\"\n",
    "\n",
    "# Keep events that influence preference and have category info\n",
    "weights = {'view': 1.0, 'addtocart': 3.0, 'transaction': 5.0}\n",
    "tmp = DF.loc[DF['categoryid'].notna(), ['visitorid','event','categoryid']].copy()\n",
    "tmp['w'] = tmp['event'].map(weights).fillna(0)\n",
    "\n",
    "# Aggregate to user-category preference strength\n",
    "uc = tmp.groupby(['visitorid','categoryid'], as_index=False)['w'].sum()\n",
    "\n",
    "# Convert to per-user distribution (so we cluster on relative preference, not absolute volume)\n",
    "user_tot = uc.groupby('visitorid')['w'].sum().rename('w_user')\n",
    "uc = uc.merge(user_tot, on='visitorid', how='left')\n",
    "uc['p'] = (uc['w'] / uc['w_user']).fillna(0)   # preference proportion in that category\n",
    "\n",
    "# Build sparse user x category matrix (values = preference share)\n",
    "users = uc['visitorid'].unique()\n",
    "cats  = uc['categoryid'].unique()\n",
    "user2idx = {u:i for i,u in enumerate(users)}\n",
    "cat2idx  = {c:i for i,c in enumerate(cats)}\n",
    "\n",
    "rows = uc['visitorid'].map(user2idx).values\n",
    "cols = uc['categoryid'].map(cat2idx).values\n",
    "vals = uc['p'].values.astype(np.float32)\n",
    "X_uc = sparse.csr_matrix((vals, (rows, cols)), shape=(len(users), len(cats)))\n",
    "\n",
    "print(f\"User x Category matrix: {X_uc.shape} (nnz={X_uc.nnz:,})\")\n",
    "\n",
    "# Dimensionality reduction for speed + denoising\n",
    "SVD_COMPONENTS = 32  # adjust (16–64 reasonable)\n",
    "svd = TruncatedSVD(n_components=SVD_COMPONENTS, random_state=42)\n",
    "U = svd.fit_transform(X_uc)   # shape (n_users, SVD_COMPONENTS)\n",
    "\n",
    "explained = svd.explained_variance_ratio_.sum()\n",
    "print(f\"SVD components: {SVD_COMPONENTS} | explained variance ≈ {explained:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67ac5c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=4 -> silhouette=0.5128\n",
      "K=6 -> silhouette=0.5306\n",
      "K=8 -> silhouette=0.5320\n",
      "Selected K=8 (silhouette=0.5320)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13292\\1741658936.py:52: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: topn_cats(x, n=5))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13292\\1741658936.py:72: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: ', '.join([f\"{int(c)} ({g.loc[g[cat_name]==c,'p'].values[0]:.2f})\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>users</th>\n",
       "      <th>median_interactions</th>\n",
       "      <th>mean_interactions</th>\n",
       "      <th>views</th>\n",
       "      <th>txns</th>\n",
       "      <th>conv_rate</th>\n",
       "      <th>top_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>257083</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.868</td>\n",
       "      <td>1.830</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "      <td>984 (0.99), 730 (0.99), 499 (0.98), 1578 (0.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24982</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.950</td>\n",
       "      <td>1.905</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.004</td>\n",
       "      <td>959 (0.97), 1625 (0.50), 1603 (0.50), 1598 (0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14275</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.021</td>\n",
       "      <td>1.988</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>5 (0.97), 1643 (0.50), 3 (0.50), 1509 (0.50), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>63485</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.950</td>\n",
       "      <td>1.906</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1625 (1.00), 1233 (1.00), 64 (0.97), 1393 (0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>32987</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.167</td>\n",
       "      <td>2.134</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1051 (0.96), 1690 (0.50), 1681 (0.50), 3 (0.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>797674</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.155</td>\n",
       "      <td>2.069</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30 (1.00), 1557 (1.00), 31 (1.00), 91 (1.00), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>18660</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.771</td>\n",
       "      <td>1.735</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1221 (0.96), 707 (0.93), 1666 (0.50), 1580 (0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>26886</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.746</td>\n",
       "      <td>1.721</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1404 (0.99), 333 (0.97), 1477 (0.97), 82 (0.50...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster   users  median_interactions  mean_interactions  views  txns  \\\n",
       "0        0  257083                1.000              1.868  1.830 0.007   \n",
       "1        1   24982                1.000              1.950  1.905 0.012   \n",
       "2        2   14275                1.000              2.021  1.988 0.007   \n",
       "3        3   63485                1.000              1.950  1.906 0.010   \n",
       "4        4   32987                1.000              2.167  2.134 0.006   \n",
       "5        5  797674                1.000              2.155  2.069 0.024   \n",
       "6        6   18660                1.000              1.771  1.735 0.008   \n",
       "7        7   26886                1.000              1.746  1.721 0.004   \n",
       "\n",
       "   conv_rate                                     top_categories  \n",
       "0      0.003  984 (0.99), 730 (0.99), 499 (0.98), 1578 (0.97...  \n",
       "1      0.004  959 (0.97), 1625 (0.50), 1603 (0.50), 1598 (0....  \n",
       "2      0.002  5 (0.97), 1643 (0.50), 3 (0.50), 1509 (0.50), ...  \n",
       "3      0.003  1625 (1.00), 1233 (1.00), 64 (0.97), 1393 (0.9...  \n",
       "4      0.002  1051 (0.96), 1690 (0.50), 1681 (0.50), 3 (0.50...  \n",
       "5      0.005  30 (1.00), 1557 (1.00), 31 (1.00), 91 (1.00), ...  \n",
       "6      0.002  1221 (0.96), 707 (0.93), 1666 (0.50), 1580 (0....  \n",
       "7      0.001  1404 (0.99), 333 (0.97), 1477 (0.97), 82 (0.50...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose K via quick silhouette on a small sample (optional but useful)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "K_CANDIDATES = [4, 6, 8]  # small sweep to keep it fast\n",
    "sample_size = min(20000, U.shape[0])\n",
    "rng = np.random.default_rng(42)\n",
    "idx_sample = rng.choice(U.shape[0], size=sample_size, replace=False) if sample_size < U.shape[0] else np.arange(U.shape[0])\n",
    "\n",
    "# Scale before KMeans (helps when features are on different scales)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "U_scaled_sample = scaler.fit_transform(U[idx_sample])\n",
    "\n",
    "best_k, best_sil = None, -1.0\n",
    "for k in K_CANDIDATES:\n",
    "    km = MiniBatchKMeans(n_clusters=k, random_state=42, batch_size=4096, n_init='auto')\n",
    "    labels_sample = km.fit_predict(U_scaled_sample)\n",
    "    sil = silhouette_score(U_scaled_sample, labels_sample, metric='euclidean')\n",
    "    print(f\"K={k} -> silhouette={sil:.4f}\")\n",
    "    if sil > best_sil:\n",
    "        best_k, best_sil = k, sil\n",
    "\n",
    "print(f\"Selected K={best_k} (silhouette={best_sil:.4f})\")\n",
    "\n",
    "# Fit on ALL users using the chosen K\n",
    "U_scaled_all = scaler.fit_transform(U)\n",
    "kmeans = MiniBatchKMeans(n_clusters=best_k, random_state=42, batch_size=4096, n_init='auto')\n",
    "user_cluster = kmeans.fit_predict(U_scaled_all)\n",
    "\n",
    "# Map cluster back to original user ids\n",
    "user_cluster_df = pd.DataFrame({'visitorid': users, 'cluster': user_cluster})\n",
    "\n",
    "# --------- Cluster profiling ---------\n",
    "# 1) Size & activity\n",
    "user_events = DF.groupby('visitorid')['event'].count().rename('interactions')\n",
    "profile_size = user_cluster_df.merge(user_events, on='visitorid', how='left')\n",
    "size_summary = profile_size.groupby('cluster').agg(\n",
    "    users=('visitorid','nunique'),\n",
    "    median_interactions=('interactions','median'),\n",
    "    mean_interactions=('interactions','mean'),\n",
    ").reset_index()\n",
    "\n",
    "# 2) Category mix per cluster (top-5 categories by average preference share)\n",
    "# Merge cluster back to user-category proportions\n",
    "uc_with_cluster = uc[['visitorid','categoryid','p']].merge(user_cluster_df, on='visitorid', how='left')\n",
    "cat_pref = uc_with_cluster.groupby(['cluster','categoryid'])['p'].mean().reset_index()\n",
    "\n",
    "def topn_cats(df, n=5):\n",
    "    return df.sort_values('p', ascending=False).head(n)\n",
    "\n",
    "top_categories = (\n",
    "    cat_pref.groupby('cluster', group_keys=False)\n",
    "    .apply(lambda x: topn_cats(x, n=5))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 3) Conversion by cluster (views -> transactions rate) for interpretability\n",
    "views = DF[DF['event']=='view'].groupby(['visitorid'])['itemid'].count().rename('views')\n",
    "txns  = DF[DF['event']=='transaction'].groupby(['visitorid'])['itemid'].count().rename('txns')\n",
    "conv_user = pd.concat([views, txns], axis=1).fillna(0)\n",
    "conv_user['conv_rate'] = np.where(conv_user['views']>0, conv_user['txns']/conv_user['views'], 0)\n",
    "\n",
    "conv_by_cluster = user_cluster_df.merge(conv_user, left_on='visitorid', right_index=True, how='left') \\\n",
    "                                 .groupby('cluster')[['views','txns','conv_rate']].mean().reset_index()\n",
    "\n",
    "# 4) Simple, readable summary table\n",
    "# Create a compact “top categories” string per cluster\n",
    "cat_name = 'categoryid'  # stays as numeric ID here; replace with your category name map if you have one\n",
    "topcats_str = (\n",
    "    top_categories\n",
    "    .sort_values(['cluster','p'], ascending=[True, False])\n",
    "    .groupby('cluster')\n",
    "    .apply(lambda g: ', '.join([f\"{int(c)} ({g.loc[g[cat_name]==c,'p'].values[0]:.2f})\"\n",
    "                                for c in g[cat_name].values.astype(int)]))\n",
    "    .rename('top_categories')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "cluster_summary = (\n",
    "    size_summary.merge(conv_by_cluster, on='cluster', how='left')\n",
    "                .merge(topcats_str, on='cluster', how='left')\n",
    "                .sort_values('cluster')\n",
    ")\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f\"{x:,.3f}\")\n",
    "cluster_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bbcfe26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAGGCAYAAADmRxfNAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOn1JREFUeJzt3QmcjXX///EPxr7vJBJCyJItibgTyk97lpJdkiWh7rRYwk2kW2UX5ReiUu7SbY+7FMmWJVQibbaSbOHP+T/e39/jnPvMmBljvjNzzMzr+XicxrnOdc65zjWHrvf1+X6+V4ZAIBAwAAAAAPCQ0efJAAAAACAECwAAAADeCBYAAAAAvBEsAAAAAHgjWAAAAADwRrAAAAAA4I1gAQAAAMAbwQIAAACAN4IFAAAAAG8ECwBIRYYMGWIZMmSI9GYgia1atcr9XvUTAFIrggWAOE2cONEd7NStWzfSm2K7d++27t27W5kyZSxbtmyWJ08eq1+/vr388st26tSpSG9euqDvQvhNv4Obb77ZPvroo0S/5pw5c2zcuHGWlr3//vt22223WaFChSxLlix2xRVXWKtWrezjjz9OsW34/PPPXSj9448/Uuw9AaQ/GQKBQCDSGwHg8qQD919++cX27t1r3377rZUrVy4i26ED1/vvv9+yZs1q7du3typVqtiZM2ds9erVNn/+fOvYsaNNnTrV0oP/9//+n7spXKU0hYlbb73V/Q70v44ffvjBJk2aZL/++qstWrTImjVrdsmv+T//8z+2bds29x1La7SPOnfubG+88YbVqFHD7rvvPitWrJjbXwobGzZssM8++8xuvPFGV6lo3LixrVy50ho1apTk2/Liiy/aE088YXv27LHSpUsn+esDgESxGwDERgcgOsv53nvvuUrB7NmzbfDgwRHZjjZt2thVV13lzvAWL1489FjPnj3tu+++8zpjfjn466+/3JnsjBkvXkSOiopyt0gpX768tWvXLnT/3nvvtUqVKrnKUWKCRWp2/vx5F3DjCnljx451oaJv37720ksvRRvC9swzz9ibb74Z0d9lUjh58qTlyJEj0psB4DLBUCgAsVKQyJ8/v7Vo0cKdadX9oLNnz1qBAgWsU6dOFzzvzz//dAdaAwYMCC3Tme077rjDcubMaUWKFLHHH3/clixZkqAx5aNHj7bjx4/b9OnTo4WKIFVRHnvssdB9nc0fNmyYlS1b1lU4dHb26aefttOnT0d7npbrbLmqHnXq1HHbrGFW//u//xtaZ/369W4bZ86cecH7Brd/4cKFoWU///yzO0NdtGhR996VK1e2GTNmxDqWfu7cufbss89aiRIl3IGZ9pv269ChQ+2aa65x21OwYEG76aabbNmyZfH2WCTlZ75U1157rRvio6Fq4f71r3+5746G/WibtG3axnPnzoXW0Zl5hUJ9P4LDq8LPpmv7FWb1O9ZrlCxZ0p588skLPlds9NqqbKkqoIpA9uzZ7eqrr7bJkydfsG5C30fb16tXL/d3Qb9brbt48eJY31/D80aOHGkVK1Z01YLY+mIeeugh93uIi/aFqnGxfbaYVY1XX33VbZO+S/p7W6tWLTfMLPidUbVCtA+C+zq8SjRr1iyrWbOm20/6u60w/+OPP8a5Txs2bOjeS98zAAhK3adKACQbHTzdc8897kx627Zt3ZCXL7/80mrXrm2ZM2e2u+++21UzpkyZ4tYJWrBggTsg04GJnDhxwv72t7+54R8KABoKogMeDflIiA8//NAd/OrgMCG6du3qgoDCUP/+/e2LL75wB3g7duxww0/Cqdqh9bp06WIdOnRwIUAHcjrA0kGaDs703m+//bZ7PNy8efPcAVzwLP2BAwfshhtuCB18Fi5c2A0P0msrNOisdTgdZGu/KYBpf+nPOgDUtuoz6IBTz1O42bhxoxuClBKf+VIdPXrUjhw54oJDOJ2pz5Url/Xr18/9VLVp0KBB7jONGTMmdNZez//pp5/sn//8p1umdYPVAIVRhaCHH37YBZitW7e69b755hv3PbsYbdftt9/u+hn0HdbvsUePHm5fKwAm5n30OfQ6+h0rUMU1rEiv9/vvv7vfe6ZMmSw5TZs2zfr06eN+r/o7pgrYli1b3PfggQcecH+P9Vneeust97m03aLvqIwYMcKee+45t5/0XTp06JALKgoPmzZtsnz58oXe67fffnP9Ivr7rcqVQjQAhKjHAgDCrV+/Xr1XgWXLlrn758+fD1x55ZWBxx57LLTOkiVL3DoffvhhtOfefvvtgTJlyoTujx071q23YMGC0LJTp04FKlas6JavXLkyzu04evSoW+fOO+9M0HZv3rzZrd+1a9doywcMGOCWf/zxx6FlV111lVv2ySefhJYdPHgwkDVr1kD//v1DywYOHBjInDlz4Pfffw8tO336dCBfvnyBzp07h5Z16dIlULx48cDhw4ejvXebNm0CefPmDZw8edLd1+fV+2ofBZcFVatWLdCiRYt4P+PgwYPd85PzM8dFz9XnPHTokHuevifNmzd3y8eMGRNt3ZifTbp37x7IkSNH4K+//got0+fVdsX05ptvBjJmzBj49NNPoy2fPHmye7/PPvss3m29+eab3Xr6/oX/3qpXrx4oUqRI4MyZM5f8Prqvdbdv3x64mJdfftmt//777wcSIvi9CP/7oP3SoUOHWD+bbkH6+1G5cuV4X1+/H73+nj17oi3fu3dvIFOmTIERI0ZEW75169ZAVFRUtOXBfap9AwCxYSgUgFirFToTqWZS0Vn41q1bu+E7waEsqkLozKfO3IefIdawHa0bpKEiGu6js8JBGoLTrVu3i26Hzm5L7ty5E7Td//73v91PnSUPp7P4ErMXQ70BDRo0CN3XGdwKFSrY999/H1qmz6IhSqrOBC1dutTNrhP8nDrmVBN5y5Yt3Z8PHz4cuqmiobPyqjqEU7VAw07C6czw9u3bXaN8QiXHZ46PhqTpORrSporOihUr3LChmO8f/tmOHTvm9oXeV2Pyd+7cedH3eeedd1z1QEOJwvenvneSkIqX+hfUHxSkSoXuHzx40A3nScz7aBYs7cOk/u760PdGVR9VFC+Vvteq2qhaEf75VVnUkLyYn1/Dv2IbAgkAQrAAEI2CgwKEQoUapzV0RjdNOavhPjqQDB60qXFXY+mDY9F1kKKD8PBgofHzGiYTc4x5QmaY0nSmwQPThNB7qQE65mvrIEkHX3o8XKlSpS54DQ1vUkAKqlatmjvoDA9Q+rNCVfDgU0NHFDQ0M5UOusNvwYMwHcyG01j3mJ5//nn3OmqQvu6669y4eA1pSenPHJ8777zThUcFlmC/h8JCzMZzBSQNl8ubN6/7PWpfBJu+FbQuRuFKrxFzf2rfxLY/Y6P+DvX1hAs+P9hfcKnvE9vvLSm+uz7+/ve/uyFkGj6nMKBJDTTbVELo8ysM63kx94GG0sX8/DpJED70EQDC0WMB4IIx5OqHULjQLbZqRtOmTd2fNc5aPRbqJbjrrrvc2HMdhOtgPCno4EwHh5qO9FIk9AJycY19jzkLt4KSxqHrTK7OQH/wwQduzH5wRh+d8RUdOMfsxQiqWrVqtPsxqxWiMe1qglZYU1Xktddec2Pi1XCsse8p+ZnjcuWVV1qTJk3cn9W/oIClfgMFUY3lF4UjndnX709hScFSVSpVbXQQHNxf8dE6CleaTSk2arBOCpf6PrH93mKjvweifg393UiMuH6nCv/hv0dVXHbt2uUmElCFUNUzXYNGPS2aDOBin1/vo7/DsX03gj0vl/r5AaRPBAsAFwQHDXOZMGHCBY+pIqFmYB3o6gBDB8KaqUln8DV7kUKJGnLDaZrYr7/+2h24hh8oqQqSEJrFSJWANWvWWL169eJdV++lAyWdhdXBVpAqLTrY1eOJoWChAzQdsGmImIa5BJvTRWd3FTh0wBc86E6s4Gxbumk2LO1jVQbiChbJ9ZkTSkOLFH40w5UqFMGZvtTkq++Ltj9IFbCEHjwrjHz11Vd2yy23JPpK47oGiyYPCK9aqIlZgk3XSfE+sdHfB1WC1DCtmZMS08Ct58d2QTtVoTSpQDh9Rn1PddMUuAp5CsMDBw50oS6+/ay/m6rEBKs0AJBYDIUCEG2KTB0M6mBeM8zEvOnMtIZ26Iy9aPiLlmvmJs3Jr2lPw4dBiXoMNA1r8DmiWWs0k01CaPy+Dpp0YK2D5Zh0hl/XUAieQZeYV3IOno3W9KeJoQN2ndVWgNJNYSr8gFkHjRoWpuARW3VFQ6USQgfjMc8Wa4hTfNOrJtdnTihVbdTPoWEzqrRI8CA6vAqig12dRY9Jv9vYhkZpzL++N7F9T/Q9VWC4GH0fVVEL3wbdVxDULFhJ9T6x0VSsqs5ov+hnbBUhTfG6bt26OF9DB/1r16512x2kqkTMaWBjfm80VEl9IHpPDU2UYLiKGVQUQPT7UnCOuY26H/O1ASA+VCwAhOjgX8EhvNE6nKZT1UGZqhrBAKGfmppS1wHQwXf4WfPgGe3x48e7oUOaClMH5Xp+8KJiFztLrIMrTU+r99Frh195WxfwU/NtcK5/DcHSUCRVOILDcXTgpqlYNRwl2IyeGHp/DS3Rdmuq1pg9BaNGjXKNrupFUWO6Duw03aiG/yxfvtz9+WL0HF0rQAe9qlxoqtl3333XBbq4JOdnTijtf+2bF154wb2npgbW2XZtl6ZB1e9YwTO2g2t9VoU1NX9rKmOFKTXB6xoPGlr3yCOPuP2qq8CrIqTGby3XdUTUPB4fDaPTNqmfQmfj9T6bN292+0pTJktSvE9c1COj/g1dKE+vHbzy9v79+900tvo96TscF4Vp/f6bN2/uApBCtMJIzKl9NTRRr6ttV0VNYUZ/5xQqg83jwSCliqKqbfr82s96reHDh7vKhvaTfn96jqpLqk5qCt7wa9IAQLxinSsKQLrUsmXLQLZs2QInTpyIc52OHTu66VeD06pqKtqSJUu6aSiHDx8e63O+//57N61o9uzZA4ULF3ZTm86fP989Z+3atQnatm+++SbQrVu3QOnSpQNZsmQJ5M6dO1C/fv3Aq6++Gm360rNnzwaGDh0auPrqq912ats0ZWz4OsGpPGOb2jXmVJ5B3377rdte3VavXh3rNh44cCDQs2dP955672LFigVuueWWwNSpUy+YVvSdd9654Pnaf3Xq1HFT2WpfaUpeTfcZnBo1tulmk/Mzx6T31eeLzZAhQ6JNl6ppWm+44Qb3Oa644orAk08+GZqiOHxK1ePHjwceeOAB95n1WPjUs/rcL7zwgptKVVPi5s+fP1CzZk33WTUVcXz0efQ8TYlbr149973Wa48fP/6CdRP6PvF9/vi8++67gaZNmwYKFCjgpnDVtMStW7cOrFq1Kt7pZkXT5ZYoUcJtl77v+jwxf19TpkwJNGzYMFCwYEG3XtmyZQNPPPHEBfto2LBh7rU0ZW7MqWf19/Gmm24K5MyZ09303dNn3bVr1wX7FADikkH/iT96AEDS09AdXYFb02RqphkgKanyo2b7S238BwAkHj0WAJKdxqqHU4+FxrpriktCBQAAaQM9FgCSnRpEdf2E6tWru0ZdjRPXGHb1WgAAgLSBYAEg2WlmKF2TQUFCjbFqUtY1MmLOIAUAAFIveiwAAAAAeKPHAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAACQzkyYMMFKly5t2bJls7p169q6desS9DxNE50hQwa76667oi3XsthuY8aMcY+fPn3aHnroIcuTJ4+VL1/eli9fHu35Wq93795J+AkBRALBAgCAdGTevHnWr18/Gzx4sG3cuNGqVavmrjVz8ODBeJ+3d+9eGzBggDVo0OCCx3799ddotxkzZrhgce+997rHp06dahs2bLA1a9bYww8/bA888IAFZ7vfs2ePTZs2zUaMGJFMnxhASuE6FgAApCOqUNSuXdvGjx/v7p8/f95KlizpKgZPPfVUrM/RhS0bNmxonTt3tk8//dT++OMPW7BgQZzvoYrGsWPHbMWKFe7+o48+6qoVo0aNslOnTlmOHDlckClcuLA1b97cunfvbnfffXcyfWIAKYWKBQAA6cSZM2dc5aBJkyahZRkzZnT3VU2Iy/PPP29FihSxLl26XPQ9Dhw4YB999FG0dVUVWb16tQsVS5YsseLFi1uhQoVs9uzZbjgWoQJIG6IivQEAACBlHD582FUfihYtGm257u/cuTPW5ygQTJ8+3TZv3pyg95g5c6blzp3b7rnnntAyVTq2bNlilSpVcoHi7bfftiNHjtigQYNs1apV9uyzz7r+jbJly7phVCVKlPD8pAAigWABAABipeFMarpWD4QCQUIoGDz44IOuEhGUOXNm1zAerlOnTtanTx/btGmTG1b11Vdf2ejRo92y+fPnJ/lnAZD8CBYAAKQTCgeZMmVyw5XC6X6xYsUuWH/37t2uabtly5ahZerJkKioKNu1a5erMgSp/0LL1CAen5UrV9r27dvttddesyeeeMJuv/12y5kzp7Vq1SrU+wEg9aHHAgCAdCJLlixWs2bNUFN1MCjofr169S5Yv2LFirZ161Y3DCp4u+OOO6xx48buz2r6DqchU3p99VTE5a+//rKePXvalClTXMjR0KyzZ8+6x/RT9wGkTlQsAABIRzTVbIcOHaxWrVpWp04dGzdunJ04ccINTZL27du7HoeRI0e64UxVqlSJ9vx8+fK5nzGX//nnn/bOO+/Y2LFj433/YcOGuQpFjRo13P369eu7qoXeX9UK3QeQOhEsAABIR1q3bm2HDh1yjdP79++36tWr2+LFi0MN3fv27XMzRV0qNV9rBvu2bdvGuc62bdtc43Z4I/h9993nGrh1fYwKFSrYnDlzEvnJAEQa17EAAAAA4I0eCwAAAADeCBYAAAAAvNFjAQBAKjJuy+uR3oTLWt+q/9eEDiDlUbEAAAAA4I1gAQAAAMAbwQIAAACAN4IFAAAAAG8ECwAAAADeCBYAAAAAvBEsAAAAAHgjWAAAAADwRrAAAAAA4I1gAQAAAMAbwQIAAACAN4IFAAAAAG8ECwAAAADeCBYAAAAAvBEsAAAAAHgjWAAAAADwRrAAAAAA4I1gAQAAAMAbwQIAAACAN4IFAAAAAG8ECwAAAADeCBYAAAAAvBEsAAAAAHgjWCBZTZgwwUqXLm3ZsmWzunXr2rp16xL0vLlz51qGDBnsrrvuirb8vffes6ZNm1rBggXd45s3b77guf369bMCBQpYyZIlbfbs2dEee+edd6xly5aenwoAAAAxESyQbObNm+cO8gcPHmwbN260atWqWbNmzezgwYPxPm/v3r02YMAAa9CgwQWPnThxwm666SZ74YUXYn3uhx9+aHPmzLGlS5fa6NGjrWvXrnb48GH32NGjR+2ZZ55xYQcAAABJi2CBZPPSSy9Zt27drFOnTlapUiWbPHmy5ciRw2bMmBHnc86dO2cPPvigDR061MqUKXPB4w899JANGjTImjRpEuvzd+zYYY0aNbJatWpZ27ZtLU+ePLZnzx732JNPPmk9evSwUqVKJeGnBAAAgBAskCzOnDljGzZsiBYAMmbM6O6vWbMmzuc9//zzVqRIEevSpUui3ldVkfXr19uRI0fc+586dcrKlStnq1evdlWTPn36JOp1AQAAED+CBZKFhh+p+lC0aNFoy3V///79sT5HB//Tp0+3adOmJfp9NdSqXbt2Vrt2bevYsaPNnDnTcubM6SoVqphMmjTJKlSoYPXr17ft27cn+n0AAAAQXVSM+0BEHDt2zA1zUqgoVKiQ12sNGTLE3YI0rEqVksyZM9vw4cNt69attnDhQmvfvr2ragAAAMAfwQLJQuEgU6ZMduDAgWjLdb9YsWIXrL97927XtB0+Y9P58+fdz6ioKNu1a5eVLVv2krdj586dNmvWLNu0aZPr7WjYsKEVLlzYWrVqZZ07d3aBJnfu3In6jAAAAPgvhkIhWWTJksVq1qxpK1asiBYUdL9evXoXrF+xYkVXSdD0scHbHXfcYY0bN3Z/1tSxlyoQCFj37t1dE3muXLnc0KyzZ8+6x4I/tQwAAAD+qFgg2Wiq2Q4dOrgZmurUqWPjxo1z08VqlijRUKQSJUrYyJEj3XUuqlSpEu35+fLlcz/Dl//++++2b98+++WXX9x9VTJEVZCYlZDXXnvNVSeCVRD1VWiI1Nq1a23RokVupqrgewAAAMAPwQLJpnXr1nbo0CE3PawatqtXr26LFy8ONXQrIGimqEvxwQcfhIKJtGnTxv3UtTLC+yo05GrEiBH2+eefh5Yp3PTv399atGjhZp5SYzcAAACSRoaAxosAAIBUYdyW1yO9CZe1vlX/e/IJQMqixwIAAACAN4IFAAAAAG/0WCBOlNvjR7kdAADgv6hYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAJMCECROsdOnSli1bNqtbt66tW7cuznXfe+89q1WrluXLl89y5sxp1atXtzfffDPaOkOGDLGKFSu6x/Pnz29NmjSxL774IvT46dOn7aGHHrI8efJY+fLlbfny5dGeP2bMGOvdu3cyfFIAABKHYAEAFzFv3jzr16+fDR482DZu3GjVqlWzZs2a2cGDB2Ndv0CBAvbMM8/YmjVrbMuWLdapUyd3W7JkSWgdhYXx48fb1q1bbfXq1S60NG3a1A4dOuQenzp1qm3YsMG9xsMPP2wPPPCABQIB99iePXts2rRpNmLEiBTaAwAAXFyGQPD/VEAM47a8HulNuKz1rdop0puAFKIKRe3atV0QkPPnz1vJkiVdxeCpp55K0Gtcf/311qJFCxs2bFisj//555+WN29eV5m45ZZb7NFHH3XVilGjRtmpU6csR44cLsgULlzYmjdvbt27d7e77747ST8nUgf+bY4f/zYDkUPFAgDicebMGVc50FCloIwZM7r7qiZcjM7drFixwnbt2mUNGzaM8z1UoVCwUDVE9FOVDIUKVTqKFy9uhQoVstmzZ7vhWIQKAMDlJirSGwAAl7PDhw/buXPnrGjRotGW6/7OnTvjfN7Ro0etRIkSrlciU6ZMNnHiRLv11lujrbNw4UJr06aNnTx50gWHZcuWufAgnTt3dsOoKlWq5Ja9/fbbduTIERs0aJCtWrXKnn32WZs7d66VLVvWZsyY4d4LAIBIIlgAQDLInTu3bd682Y4fP+4qFurRKFOmjDVq1Ci0TuPGjd06Ci/qmWjVqpVr4C5SpIhlzpzZNYyHU59Gnz59bNOmTbZgwQL76quvbPTo0W7Z/PnzI/ApAQD4L4ZCAUA8VC1QxeHAgQPRlut+sWLF4nyehkuVK1fOzQjVv39/u++++2zkyJHR1tGMUFrnhhtusOnTp1tUVJT7GZuVK1fa9u3brVevXq5icfvtt7vnK4zoPgAAkUawAIB4ZMmSxWrWrOmqDkFq3tb9evXqJfh19BwNi0rMOn/99Zf17NnTpkyZ4kKOhmadPXvWPaafug8AQKQRLADgIjSMSUOVZs6caTt27LAePXrYiRMn3NAkad++vQ0cODC0vioT6pf4/vvv3fpjx45117Fo166de1zPffrpp23t2rX2ww8/uOZw9VT8/PPPdv/991/w/ppJShWKGjVquPv169d318pQD4ZmqtJ9AAAijR4LALiI1q1bu+tLqHF6//79bnjT4sWLQw3d+/btc0OfghQcNF3sTz/9ZNmzZ3cXwps1a5Z7HVHVQY3fCirqryhYsKCbzvbTTz+1ypUrR3vvbdu2ucZt9WIEaViVhj81aNDAKlSoYHPmzEmxfQEAQFy4jgXixFzp8WOudACRwL/N8ePfZiByGAoFAAAAwBvBAgAAAIA3eiwApHkMHYkfQ0cAAEmBigUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8pdtgMWHCBCtdurRly5bN6tata+vWrYtz3WnTplmDBg0sf/787takSZML1u/YsaNlyJAh2q158+ahx0+fPm0PPfSQ5cmTx8qXL2/Lly+P9vwxY8ZY7969k+GTAgAAAMkvXQaLefPmWb9+/Wzw4MG2ceNGq1atmjVr1swOHjwY6/qrVq2ytm3b2sqVK23NmjVWsmRJa9q0qf3888/R1lOQ+PXXX0O3t956K/TY1KlTbcOGDe75Dz/8sD3wwAMWCATcY3v27HHhZcSIEcn8yQEAAIDkkS6DxUsvvWTdunWzTp06WaVKlWzy5MmWI0cOmzFjRqzrz5492x599FGrXr26VaxY0V577TU7f/68rVixItp6WbNmtWLFioVuqm4E7dixw+644w6rXLmy9ezZ0w4dOmSHDx92j/Xo0cNeeOEFV80AAAAAUqN0FyzOnDnjKgcazhSUMWNGd1/VhIQ4efKknT171goUKHBBZaNIkSJWoUIFFxZ+++230GOqiqxevdpOnTplS5YsseLFi1uhQoVcaNFwrLvvvjsJPyUAAACQsqIsnVGV4Ny5c1a0aNFoy3V/586dCXqNv//973bFFVdECycaBnXPPffY1Vdfbbt377ann37abrvtNhdWMmXKZJ07d7YtW7a4CokCxdtvv21HjhyxQYMGuUDy7LPP2ty5c61s2bKuclKiRIkk/+wAAABAckl3FQtfo0aNcgHg/fffd5WGoDZt2rihTtddd53dddddtnDhQvvyyy9daJDMmTO7hnH1U2j5TTfdZP3797c+ffrYpk2bbMGCBfbVV1/ZDTfc4JYBkZqIINwjjzziJiIYN25caBkTEQAAgNiku2ChaoEqCAcOHIi2XPfVFxGfF1980QWLpUuXWtWqVeNdt0yZMu69vvvuu1gfVyP49u3brVevXi583H777ZYzZ05r1apVKIwAkZqIQBSe165d66pz4ZiIAAAAxCbdBYssWbJYzZo1ozVeBxux69WrF+fzRo8ebcOGDbPFixdbrVq1Lvo+P/30k+uxUC9FTH/99Zdr4J4yZYoLORqapZ4N0U/dByI5EYGChqoOWl/VtnBMRAAAAGKT7oKF6AyvzqrOnDnTHSTpYOjEiRPu4Ezat29vAwcODK2vA6XnnnvOHaxpyMn+/fvd7fjx4+5x/XziiSfc2d29e/e6g7Q777zTypUr584ex6SAogpFjRo13P369evbe++953owxo8f7+4DkZqIQEFDQ530nVZ4iImJCAAAQGzSZbBo3bq1G9akxmmdud28ebOrRAQbuvft2+euQxE0adIkdxB33333uYOo4E2vIao6KBToLK7GnHfp0sVVRT799FM3BW24bdu2ucbtoUOHhpbpdVu0aOHGvut1Xn755RTbF0ibExEo+CZ2IgIF6aioqDh7fTQRgcKFKiQa8hQ+EcGrr77qJiIIhurYhlgBQHqQ1P1vQ4YMcZVmDZsOrvPFF1+EHqf/DZeDdDcrVJB6G3SLTcweB1Uh4pM9e3Z35jYhqlSpYt9++220ZTrLPHHiRHcDUnoiAn3fgxMRqAKiYKt+DTVtxyY4EUE4VftiTkSg4YNaNn/+/BT5PABwufW/aXiqQoUmwNDJll27drlp6ePqf7vxxhvdv8c6waP+N/ViBmeJVFjQqAb1cKpi/M9//tOto17OwoULR+t/W7Roket/U/+o/i0P9r+tX78+AnsD6Um6rFgAaUFyTESgKpsav0uVKuWqFrr98MMPbgYznXmLDRMRAEDy978pKKhKoWChYap6jz///NONdBD633A5IFgAqVRyTESgMrr+J6XhgcGbhkqp3yK2qhwTEQBAyl2IN/w9VKHImzevG5oq9L/hcpAqh0KN2/J6pDfhsta36v81oSPtU6m9Q4cOLiDUqVPHldtjTkSgMvrIkSPdfZ2xUi/EnDlzQhMRSK5cudytYMGC7hZz6JMqILqifEImIlAI0fszEQGA9Ci5LsQrukaWrpul4KHgsGzZMhcehAvx4nKQKoMFgP9ORKByt/7HoZCgMnrMiQh0piy2iQjC6ToYagy8FMGJCFTVCNLr6n9gakJUEFGAAQD49b8FNW7c2P2bq/CingkNOVUDt/o26H/D5YBgAaRySTkRQWzieg4TEQBA8vS/aUan2C7Eq/41zbqn2w033GDXXHONTZ8+PdoU+TH739SvoUpyeP+bKspAcqDHAgAAIJVdiDf4uppmNib63xApBAsAAIDL+EK8eu7TTz/tLsSrmfrUHK6eCl0r6P7777/g/bkQLyKFoVBABDERQfyYiABAapTU/W+qOqjxW0FF/RWaZKN27dpuinBNLxuO/jdEEsECAADgMu5/UxO3Kg4JQf8bIomhUACAy4ZmtdFQEB1I6YrF69ati3NdDTXRGdj8+fO7m6bmDF9fY8k1bed1113nmlY1faeGoPzyyy+hdTQ+Xddv0YXDdGVjNc2GGzNmjPXu3TuZPi0ApC0ECwDAZWHevHlubLqGf2zcuNFd8KtZs2buavBxnfVt27atm/1GFx4rWbKkNW3a1I07F831r9fR2HX91BnfXbt2uasTB+kiYxqvruc//PDD7urGgUDAPbZnzx4XXkaMGJFCewAAUjeGQgEALgsvvfSSdevWLdTgOnnyZPvoo49cQ+tTTz11wfq6onA4Taupufk1+44qE7oqsS4gFk6Nq7qYpMa4lypVyjXWKmhonHqZMmXctJwaw164cGHXcKumWlUzkL7Q/xY/+t8QFyoWAICIU+OqKgfhVxrWuHDdVzUhIVSh0PCnAgUKxLnO0aNHLUOGDJYvXz53X1WR1atX26lTp2zJkiXuasa6DoFCi4Zj3X333Unw6QAgfaBiAQCIOFUJNLd+cNacIN3XbDgJoX4K9VGEh5OYc/trHQ2fClYhNGWnpuCsVKmSCxSaTefIkSNuNh8NtXr22WfdVZDLli3rKiclSpRIgk8LAGkTwQIAkOrpasUKAAoDqjTEpEqGrjis/glN7RmUOXNm1zAeTkOx+vTpY5s2bbIFCxbYV1995S5epmUaagUAiB1DoQAAEadqgebqP3DgQLTlul+sWLF4n/viiy+6YLF06VKrWrVqnKFCFxZTz0V8PRNqBN++fbubJlQhRRcZ04xSen7MKUIBANERLAAAEZclSxarWbOma7wOOn/+vLtfr169OJ+nSoKuMqyLj9WqVSvOUKF5/TWVrC4sFhcNlerZs6dNmTLFhRwNzdLzg6+j+wCAuBEsAACXBU01q+lddXVhzdakWZlOnDgRmiVKMz0NHDgwtL5mbNJUsup90LUvdIVj3Y4fPx4KA7ri8Pr1610ztoJBcB01i8ekgKIKRY0aNdz9+vXruylq1YOh2aR0HwAQN3osAACXhdatW9uhQ4dc47QO/qtXr+4qEcGGbk0Rq5migtQroYCg8BBO18EYMmSIu57FBx984JbptWIOeWrUqFHo/rZt21zj9ubNm0PL9Loa/qSL8FWoUMHmzJmTbJ8dANICggUA4LKh3gbdYhOzx2Hv3r3xvpaqGMGL3V1MlSpV3HCpcAoxEydOdDcAwMUxFAoAAACAN4IFAAAAAG8MhQIAJIlxW16P9CZc1vpW/b8mdABIq6hYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAAAAeCNYAAAAAPBGsAAAAADgjWABAAAAwBvBAgAAAIA3ggUAAAAAbwQLAAAAAN4IFgAAAAC8ESwAAACQKk2YMMFKly5t2bJls7p169q6deviXHf79u127733uvUzZMhg48aNi/e1R40a5dbr27dvtOX9+vWzAgUKWMmSJW327NnRHnvnnXesZcuWll4RLAAAAJDqzJs3zx3kDx482DZu3GjVqlWzZs2a2cGDB2Nd/+TJk1amTBkXGIoVKxbva3/55Zc2ZcoUq1q1arTlH374oc2ZM8eWLl1qo0ePtq5du9rhw4fdY0ePHrVnnnnGhZ30imABAACAVOell16ybt26WadOnaxSpUo2efJky5Ejh82YMSPW9WvXrm1jxoyxNm3aWNasWeN83ePHj9uDDz5o06ZNs/z580d7bMeOHdaoUSOrVauWtW3b1vLkyWN79uxxjz355JPWo0cPK1WqlKVXBAsAAACkKmfOnLENGzZYkyZNQssyZszo7q9Zs8brtXv27GktWrSI9tpBqoqsX7/ejhw54t7/1KlTVq5cOVu9erWrmvTp08fSs6hIbwAAAABwKTT86Ny5c1a0aNFoy3V/586diX7duXPnuoCgoVCx0VCrdu3auepH9uzZbebMmZYzZ05XqXjjjTds0qRJ9uqrr1qhQoVs6tSpVrlyZUtPCBYAAABI93788Ud77LHHbNmyZa4ZPC5Dhgxxt6ChQ4e66kbmzJlt+PDhtnXrVlu4cKG1b9/eVTXSE4ZCAQAAIFVRRSBTpkx24MCBaMt1/2KN2XFRCFDj9/XXX29RUVHu9p///MdeeeUV92dVSGJSdWTWrFk2bNgwW7VqlTVs2NAKFy5srVq1cpWPY8eOWXpCsAAAAECqkiVLFqtZs6atWLEitOz8+fPufr169RL1mrfccourNmzevDl0U5O2Grn1ZwWZcIFAwLp37+6ayHPlyuWCx9mzZ91jwZ+xhZG0jKFQAAAASHU01WyHDh3cwX+dOnXcdSlOnDjhZokSDUUqUaKEjRw5MtTw/fXXX4f+/PPPP7vAoFCgBuzcuXNblSpVor2H+icKFix4wXJ57bXXXHUieN2K+vXruyFSa9eutUWLFrmZqvLly2fpCcECAAAAqU7r1q3t0KFDNmjQINu/f79Vr17dFi9eHGro3rdvn5spKuiXX36xGjVqhO6/+OKL7nbzzTe7YUyXQkOuRowYYZ9//nloWZ06dax///5uRqkiRYq4xu70hmABAACAVKlXr17uFpuYYUFX3NbwpUsRV+BQeNm7d+8FywcNGuRu6RU9FgAAAAC8ESwAAAAAeGMoFAAAAFLcuC2vR3oTLmt9q/5fE3pqQsUCAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOCNYAEAAADAG8ECAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOCNYAEAAADAG8ECAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOCNYAEAAADAG8ECAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOCNYAEAAADAG8ECAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOCNYAEAAADAG8ECAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOCNYAEAAADAG8ECAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOCNYAEAAADAG8ECAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOCNYAEAAADAG8ECAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOCNYAEAAADAG8ECAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOCNYAEAAADAG8ECAAAAgDeCBQAAAABvBAsAAAAA3ggWAAAAALwRLAAAAAB4I1gAAAAA8EawAAAAAOAtKiErBQIBO3bsmF0u/jp+KtKbcFn7888/k+R12M/Jv5/Zx/Hju5wy2M8pg/2cMvi3OfnxXU5d+zmp5M6d2zJkyBDvOhkCSg0J+GB58+ZNsg0DAAAAkHocPXrU8uTJ4x8sLreKxeVEoatkyZL2448/XnRnI/HYz8mPfZwy2M8pg/2cMtjPyY99nDLYz0lTsUjQUCi9CDs5fto/7KPkx35OfuzjlMF+Thns55TBfk5+7OOUwX72Q/M2AAAAAG8ECwAAAADeCBaesmbNaoMHD3Y/kXzYz8mPfZwy2M8pg/2cMtjPyY99nDLYz0kjQc3bAAAAABAfKhYAAAAAvBEsAAAAAHgjWAAAAADwRrDwMGHCBCtdurRly5bN6tata+vWrYv0JqU5n3zyibVs2dKuuOIKdz2VBQsWRHqT0pyRI0da7dq13YVvihQpYnfddZft2rUr0puV5kyaNMmqVq0amiO9Xr16tmjRokhvVpo2atQo9+9G3759I70pacqQIUPcfg2/VaxYMdKblSb9/PPP1q5dOytYsKBlz57drrvuOlu/fn2kNytN0XFczO+zbj179oz0pqVKBItEmjdvnvXr18/NILBx40arVq2aNWvWzA4ePBjpTUtTTpw44fatQhySx3/+8x/3D+jatWtt2bJldvbsWWvatKnb90g6V155pTvQ3bBhgzsw+Nvf/mZ33nmnbd++PdKbliZ9+eWXNmXKFBfmkPQqV65sv/76a+i2evXqSG9SmnPkyBGrX7++Zc6c2Z2E+Prrr23s2LGWP3/+SG9amvu3Ivy7rP8Pyv333x/pTUuVmBUqkVSh0Fne8ePHu/vnz593l4Lv3bu3PfXUU5HevDRJZxDef/99d0YdyefQoUOucqHA0bBhw0hvTppWoEABGzNmjHXp0iXSm5KmHD9+3K6//nqbOHGiDR8+3KpXr27jxo2L9GalqYqFqsebN2+O9KakaTqW+Oyzz+zTTz+N9KakK6pwLly40L799lt33IFLQ8UiEc6cOePOOjZp0iS0LGPGjO7+mjVrIrptgK+jR4+GDnqRPM6dO2dz5851VSENiULSUgWuRYsW0f6NRtLSQZeGqJYpU8YefPBB27dvX6Q3Kc354IMPrFatWu7MuU721KhRw6ZNmxbpzUrzx3ezZs2yzp07EyoSiWCRCIcPH3YHBkWLFo22XPf3798fse0CfKnyprM1Kr9XqVIl0puT5mzdutVy5crlLsD0yCOPuApcpUqVIr1ZaYoCm4anqncIyVexf+ONN2zx4sWud2jPnj3WoEEDO3bsWKQ3LU35/vvv3f695pprbMmSJdajRw/r06ePzZw5M9KblmapEvfHH39Yx44dI70pqVZUpDcAwOV1pnfbtm2Ml04mFSpUcMNHVBV69913rUOHDm7IGeEiafz444/22GOPuTHSmlQDyeO2224L/Vk9LAoaV111lb399tsM60viEz2qWPzjH/9w91Wx0L/PkydPdv92IOlNnz7dfb9VjUPiULFIhEKFClmmTJnswIED0ZbrfrFixSK2XYCPXr16uXGlK1eudI3GSHpZsmSxcuXKWc2aNd0ZdU1M8PLLL0d6s9IMDVHVBBrqr4iKinI3BbdXXnnF/VmVZiS9fPnyWfny5e27776L9KakKcWLF7/gpMO1117LsLNk8sMPP9jy5cuta9eukd6UVI1gkciDAx0YrFixItqZBd1nvDRSG83foFChYTkff/yxXX311ZHepHRD/26cPn060puRZtxyyy1uuJmqQsGbzviqB0B/1gkhJE+z/O7du92BMJKOhqTGnPr7m2++cdUhJL3XX3/d9bKoPwuJx1CoRNJUsypF6n9aderUcTOOqBGzU6dOkd60NPc/rPCzYBrLqwMENRaXKlUqotuWloY/zZkzx/71r3+5a1kE+4Ty5s3r5k1H0hg4cKArset7q7Ho2uerVq1yY6eRNPT9jdkblDNnTncNAHqGks6AAQPc9YV0gPvLL7+4adcV2tq2bRvpTUtTHn/8cbvxxhvdUKhWrVq5a2VNnTrV3ZD0J3kULHRcp+omEo+9l0itW7d203IOGjTIHYhpOkM1ssVs6IYfzfffuHHjaIFO9JdfzYPwp+ZAadSoUbTl+keWBrakoyE67du3d/OkK7RpbLpCxa233hrpTQMuyU8//eRCxG+//WaFCxe2m266yV0HR39G0tGU9qok66TE888/76rJOompChySloZAaYiZZoOCH65jAQAAAMAbPRYAAAAAvBEsAAAAAHgjWAAAAADwRrAAAAAA4I1gAQAAAMAbwQIAAACAN4IFAAAAAG8ECwAAAADeCBYAkI5kyJDBFixYEOnNAACkQQQLAEhD9u/fb71797YyZcpY1qxZrWTJktayZUtbsWJFkr/XqlWrXFD5448/kvy1AQCpT1SkNwAAkDT27t1r9evXt3z58tmYMWPsuuuus7Nnz9qSJUusZ8+etnPnTrscBQIBO3funEVF8b8kAEjNqFgAQBrx6KOPugrCunXr7N5777Xy5ctb5cqVrV+/frZ27doEVRw2b97slimkyA8//OAqHvnz57ecOXO61/v3v//tHm/cuLFbR4/pOR07dnT3z58/byNHjrSrr77asmfPbtWqVbN33333gvddtGiR1axZ01VWVq9enQJ7CACQnDg9BABpwO+//26LFy+2ESNGuAAQk6oYiaFKx5kzZ+yTTz5xr/v1119brly53BCr+fPnuwCza9cuy5MnjwsRolAxa9Ysmzx5sl1zzTXuue3atbPChQvbzTffHHrtp556yl588UU3bEvhBACQuhEsACAN+O6779yQoooVKybp6+7bt8+FBw2rEoWAoAIFCrifRYoUCQWX06dP2z/+8Q9bvny51atXL/QcVSSmTJkSLVg8//zzduuttybp9gIAIodgAQBpgEJFcujTp4/16NHDli5dak2aNHEho2rVqvEGnJMnT14QGFT1qFGjRrRltWrVSpZtBgBEBsECANIADTlS38KlNGhnzJjxglCiZu9wXbt2tWbNmtlHH33kwoWGOY0dO9bNPBWb48ePu59av0SJEtEeUy9FuNiGbAEAUi+atwEgDdCwJAWACRMm2IkTJy54PLYpYdXzIL/++mu05u2Y1E/xyCOP2HvvvWf9+/e3adOmueVZsmRxPzWjU1ClSpVcgNAQqnLlykW76XUAAGkXwQIA0giFCh3k16lTxzVWf/vtt7Zjxw575ZVXQv0O4YIH+0OGDHHrqsqgakS4vn37uulq9+zZYxs3brSVK1fatdde6x676qqrXJVk4cKFdujQIVetyJ07tw0YMMAef/xxmzlzpu3evds979VXX3X3AQBpF8ECANIINUnrIF7TwKqyUKVKFdfroIvjTZo06YL1M2fObG+99ZYbPqW+iRdeeMGGDx8ebR0FFc0MpTDRvHlzN4XtxIkT3WMa6jR06FA3u1PRokWtV69ebvmwYcPsueeec8Omgs9TaNH0swCAtCtDILk6/gAAAACkG1QsAAAAAHgjWAAAAADwRrAAAAAA4I1gAQAAAMAbwQIAAACAN4IFAAAAAG8ECwAAAADeCBYAAAAAvBEsAAAAAHgjWAAAAADwRrAAAAAA4I1gAQAAAMB8/X/3Jp9444646AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fmt_compact(n: float) -> str:\n",
    "    \"\"\"1234 -> 1.23K; 1234567 -> 1.23M; otherwise int.\"\"\"\n",
    "    n = float(n)\n",
    "    a = abs(n)\n",
    "    if a >= 1_000_000:  return f\"{n/1_000_000:.2f}M\"\n",
    "    if a >= 1_000:      return f\"{n/1_000:.2f}K\"\n",
    "    return f\"{int(n)}\"\n",
    "\n",
    "def plot_bar_no_y(x_labels, values, title, xlabel=\"\", fmt_fn=str, color=\"#8EC9F0\", figsize=(7,4)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    bars = ax.bar(x_labels, values, color=color, edgecolor=\"none\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    # remove y-axis\n",
    "    ax.set_yticks([])\n",
    "    for spine in (\"top\",\"right\",\"left\"):\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.grid(False)\n",
    "\n",
    "    # data labels\n",
    "    for bar, v in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2,\n",
    "                bar.get_height(),\n",
    "                fmt_fn(v),\n",
    "                ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---- Use with your cluster_summary ----\n",
    "# 1) Users per cluster\n",
    "plot_bar_no_y(\n",
    "    x_labels=cluster_summary[\"cluster\"].astype(str),\n",
    "    values=cluster_summary[\"users\"].values,\n",
    "    title=\"Users per Cluster\",\n",
    "    xlabel=\"Cluster\",\n",
    "    fmt_fn=fmt_compact,\n",
    "    color=\"#8EC9F0\",\n",
    "    figsize=(8,4)\n",
    ")\n",
    "\n",
    "# (Optional) 2) Avg conversion rate (%) per cluster\n",
    "if \"conv_rate\" in cluster_summary.columns:\n",
    "    plot_bar_no_y(\n",
    "        x_labels=cluster_summary[\"cluster\"].astype(str),\n",
    "        values=(cluster_summary[\"conv_rate\"] * 100.0).values,\n",
    "        title=\"Avg Conversion Rate per Cluster\",\n",
    "        xlabel=\"Cluster\",\n",
    "        fmt_fn=lambda v: f\"{v:.2f}%\",\n",
    "        color=\"#8FD19E\",\n",
    "        figsize=(8,4)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3beee97",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "Largest & Highest-Intent Cohort\n",
    "\n",
    "Cluster 5 is the biggest group (~797.7K users) and shows the highest conversion rate ~0.47%.\n",
    "\n",
    "This cohort concentrates a large share of purchasing and should be the primary target for personalization and monetization.\n",
    "\n",
    "Additional High-Intent Cohort\n",
    "\n",
    "Cluster 1 is smaller (~25.0K users) but strong with ~0.41% conversion—high purchase propensity despite size.\n",
    "\n",
    "Mid-Tier Converters\n",
    "\n",
    "Clusters 3 (~63.5K, ~0.33%), 0 (~257.1K, ~0.25%), 2 (~14.3K, ~0.24%), 6 (~18.7K, ~0.23%), and 4 (~33.0K, ~0.22%) show moderate purchase intent.\n",
    "\n",
    "C0 is large but only mid-performing, suggesting room for improvement via relevance and nudges.\n",
    "\n",
    "Lowest-Intent Cohort\n",
    "\n",
    "Cluster 7 (~26.9K) has the lowest conversion ~0.14%, indicating “window shoppers” who need re-engagement or lower-friction offers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876542a4",
   "metadata": {},
   "source": [
    "## Business Implications & Limitations \n",
    "\n",
    "**Business implications (what the current models enable)**\n",
    "\n",
    "1. Lift conversions with low latency:\n",
    "Item-Cosine (BM25) gives the best offline scores among tested models. It’s fast (sparse dot-products + caching), so we can safely use it for real-time or near-real-time product carousels.\n",
    "\n",
    "2. Stronger intent capture vs popularity:\n",
    "Co-visitation/cosine explicitly recommends items often co-viewed/co-purchased together, which typically lifts add-to-cart and basket size compared to “Top sellers”.\n",
    "\n",
    "3. Merchandising levers via reranking:\n",
    "The hybrid reranker (base similarity + popularity, freshness, category conversion rate, user-category affinity) lets business teams tune trade-offs (growth of new items, margin, category pushes) without retraining.\n",
    "\n",
    "4. Audience strategy:\n",
    "The user clusters reveal segments (e.g., high-conversion “decisive” users vs casual browsers). You can target CRM journeys, homepage slots, and promo mixes per cluster.\n",
    "\n",
    "\n",
    "\n",
    "**Limitations (why scores aren’t higher yet)**\n",
    "\n",
    "1. Implicit-only signals & label noise:\n",
    "We treat views/transactions as preferences; no explicit ratings, possible bot/accidental views, and non-purchase reasons (stockouts, price shocks) dilute signal.\n",
    "\n",
    "2. Sparsity & cold-start:\n",
    "Many users/items have few interactions; brand/price/text features were limited, so unseen items/users fall back to popularity or category heuristics.\n",
    "\n",
    "3. Short context / no sequences:\n",
    "Current models don’t leverage session order (e.g., last N clicks). You’ll miss short-term intent spikes captured by sequential models.\n",
    "\n",
    "4. Popularity bias:\n",
    "Similarity and reranking still reward already-popular items; without explicit diversity/coverage constraints, long-tail exposure can regress.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
